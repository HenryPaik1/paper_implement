{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contents\n",
    "- preprocess input review\n",
    "\n",
    "### Appendix: BiLSTM\n",
    "- Model\n",
    "- Train\n",
    "- Validation\n",
    "- Test\n",
    "- Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import csv\n",
    "PATH = '/PATH/TO/IMDB_Dataset.csv'\n",
    "df = pd.read_csv(PATH)\n",
    "df['sentiment'] = df['sentiment'].map(lambda x: 1 if x== 'positive' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    \n",
    "    text = text.lower()\n",
    "    \n",
    "    #Replace html\n",
    "    text = re.sub('(<.*?\\>)', ' ', text)\n",
    "    \n",
    "    #Convert www.* or https?://* to URL\n",
    "    text = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))','URL',text)\n",
    "\n",
    "    #Convert @username to AT_USER\n",
    "    text = re.sub('@[^\\s]+','AT_USER',text)\n",
    "\n",
    "    #Remove additional white spaces\n",
    "    text = re.sub('[\\s]{2,}', ' ', text)\n",
    "\n",
    "    #Replace #word with word\n",
    "    text = re.sub(r'#([^\\s]+)', r'\\1', text)\n",
    "    \n",
    "    #trim\n",
    "    text = text.strip('\\'\"')\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review'] = df['review'].map(preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "nlp.remove_pipe('ner')\n",
    "\n",
    "def tokenize(paragraph):\n",
    "    obj_ = ''\n",
    "    doc = nlp(paragraph)\n",
    "    tokens = [tok.text for tok in doc]\n",
    "    for sent in doc.sents:\n",
    "        obj_ += ' <sos> ' + ' '.join(tok for tok in tokens[sent.start: sent.end] if tok is not None).lower() + ' <eos>'\n",
    "    return obj_.strip()\n",
    "\n",
    "df['review'] = df['review'].map(tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<sos> i thought this was a wonderful way to spend time on a too hot summer weekend , sitting in the air conditioned theater and watching a light - hearted comedy . <eos> <sos> the plot is simplistic , but the dialogue is witty and the characters are likable ( even the well bread suspected serial killer ) . <eos> <sos> while some may be disappointed when they realize this is not match point 2 : risk addiction <eos> <sos> , i thought it was proof that woody allen is still fully in control of the style many of us have grown to love . <eos> <sos> this was the most i \\'d laughed at one of woody \\'s comedies in years <eos> <sos> ( dare i say a decade ? ) . <eos> <sos> while i \\'ve never been impressed with scarlet johanson , in this she managed to tone down her \" sexy \" image and jumped right into a average , but spirited young woman . <eos> <sos> this may not be the crown jewel of his career , but it was wittier than \" devil wears prada \" and more interesting than \" superman \" a great comedy to go see with friends . <eos>'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize(df['review'].iloc[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- save dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = '/PATH/TO/SAVE/review_dataset.json'\n",
    "df.to_json(fn, orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset by torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/henry/anaconda3/envs/torch37/lib/python3.7/site-packages/torchtext/data/field.py:150: UserWarning: Field class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from torchtext import data\n",
    "import os\n",
    "from torchtext.data import TabularDataset\n",
    "import torchtext.vocab as vocab\n",
    "\n",
    "TEXT = data.Field(sequential=True,\n",
    "                  use_vocab=True,\n",
    "                  tokenize=str.split,\n",
    "                  lower=True,\n",
    "                  batch_first=True,)\n",
    "\n",
    "LABEL = data.Field(sequential=False,\n",
    "                   use_vocab=False,\n",
    "                   batch_first=False,\n",
    "                   preprocessing = lambda x: int(x),\n",
    "                   is_target=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = TabularDataset(\n",
    "    path='./Data/PATH/TO/SAVE/review_dataset.json',\n",
    "    skip_header=True,\n",
    "    format='json',\n",
    "    fields={'review': ('text', TEXT),\n",
    "            'sentiment': ('label', LABEL)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/henry/anaconda3/envs/torch37/lib/python3.7/site-packages/torchtext/data/example.py:13: UserWarning: Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.', UserWarning)\n"
     ]
    }
   ],
   "source": [
    "## if you have train, test set,\n",
    "# train_data, validation_data = TabularDataset.splits(\n",
    "#     path='.', \n",
    "#     train='/PATH/TO/SAVE/review_dataset_train.json', \n",
    "#     test='/PATH/TO/SAVE/review_dataset_test.json', \n",
    "#     format='json',\n",
    "#     fields={'review': ('text', TEXT),\n",
    "#             'sentiment': ('label', LABEL)}, skip_header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '/PATH/TO/glove'\n",
    "FILE = PATH + '/glove.840B.300d.txt'\n",
    "TEXT.build_vocab(data, vectors=vocab.Vectors(name=FILE,), min_freq=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "874"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT.vocab.freqs['positive']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# BiLSTM tutorial part\n",
    "\n",
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "class net(nn.Module):\n",
    "    def __init__(self, voc_size, emb_size, hidn_size):\n",
    "        super().__init__()\n",
    "        self.voc_size = voc_size\n",
    "        self.emb_size = emb_size\n",
    "        self.hidn_size = hidn_size\n",
    "        self.emb = nn.Embedding(num_embeddings=voc_size, embedding_dim=emb_size) # in: (bs, seq_len); out: (bs, seq_len, emb_size)\n",
    "        self.lstm = nn.LSTM(input_size=emb_size, hidden_size=hidn_size, bidirectional=True) # in: (seq_len, batch, input_size); hidn in: (num_layers * num_directions, batch, hidden_size)\n",
    "        self.lm_out = nn.Linear(hidn_size*2, voc_size) # input concatenated_out: (seq_len, bs, hidn_dim) -> permute: (bs, seq_len, hidn_dim) \n",
    "    \n",
    "    def init_state(self, bs):\n",
    "        return (torch.zeros(size=(2, bs, self.hidn_size)), torch.zeros(size=(2, bs, self.hidn_size)))\n",
    "        \n",
    "    def forward(self, x, prev_state):\n",
    "        state_h, state_c = prev_state\n",
    "        bs = len(x)\n",
    "        emb = self.emb(x)\n",
    "        emb = emb.permute(1,0,-1)\n",
    "        out, (state_h, state_c) = self.lstm(emb, (state_h[:,:bs,:].contiguous(), state_c[:,:bs,:].contiguous()))\n",
    "        \n",
    "        forward_out = out[:, :, :self.hidn_size]\n",
    "        backward_out = out[:, :, :self.hidn_size:]\n",
    "        concat_h = torch.cat([forward_out[:-2], backward_out[2:]], dim=2) # ignore predict <sos>, <eos>\n",
    "        final_out = self.lm_out(concat_h.permute(1,0,2)) \n",
    "        return final_out.view(final_out.size()[0]*final_out.size()[1], final_out.size()[-1]), (state_h, state_c)\n",
    "\n",
    "def init_weight(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            nn.init.xavier_normal_(param.data)\n",
    "        if 'bias' in name:\n",
    "            nn.init.constant_(param.data, 0)\n",
    "\n",
    "def repackage_hidden(h):\n",
    "    \"\"\"\n",
    "    - Wraps hidden states in new Tensors, to detach them from their history.(official doc)\n",
    "    - Trim backpropagation to avoide vanishing/exploding gradient and release memory by detach tensor from graph\n",
    "    \"\"\"\n",
    "    if isinstance(h, torch.Tensor):\n",
    "        return h.detach()\n",
    "    else:\n",
    "        return tuple(repackage_hidden(v) for v in h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = net(voc_size=len(TEXT.vocab), emb_size=300, hidn_size=50)\n",
    "model.apply(init_weight)\n",
    "model.emb.weight.data.copy_(TEXT.vocab.vectors)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BucketIterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/henry/anaconda3/envs/torch37/lib/python3.7/site-packages/torchtext/data/iterator.py:48: UserWarning: BucketIterator class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
      "The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.\n",
      "The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.\n",
      "The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.\n"
     ]
    }
   ],
   "source": [
    "bs = 5\n",
    "train_iter, valid_iter, test_iter = data.BucketIterator.splits(datasets=(train_data, validation_data, test_data),\n",
    "                                                               batch_size=bs,\n",
    "                                                               device=-1,\n",
    "                                                               sort_key=lambda x: len(x.text), \n",
    "                                                               sort=False,\n",
    "                                                               repeat=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- initialize gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |       0 B  |   30418 KB |   91807 KB |   91807 KB |\n",
      "|       from large pool |       0 B  |   29795 KB |   89386 KB |   89386 KB |\n",
      "|       from small pool |       0 B  |    1102 KB |    2421 KB |    2421 KB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |       0 B  |   30418 KB |   91807 KB |   91807 KB |\n",
      "|       from large pool |       0 B  |   29795 KB |   89386 KB |   89386 KB |\n",
      "|       from small pool |       0 B  |    1102 KB |    2421 KB |    2421 KB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |       0 B  |   45056 KB |   45056 KB |   45056 KB |\n",
      "|       from large pool |       0 B  |   43008 KB |   43008 KB |   43008 KB |\n",
      "|       from small pool |       0 B  |    2048 KB |    2048 KB |    2048 KB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |       0 B  |   15187 KB |   46649 KB |   46649 KB |\n",
      "|       from large pool |       0 B  |   13212 KB |   39637 KB |   39637 KB |\n",
      "|       from small pool |       0 B  |    1975 KB |    7011 KB |    7011 KB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |       0    |      10    |      20    |      20    |\n",
      "|       from large pool |       0    |       2    |       6    |       6    |\n",
      "|       from small pool |       0    |       9    |      14    |      14    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |       0    |      10    |      20    |      20    |\n",
      "|       from large pool |       0    |       2    |       6    |       6    |\n",
      "|       from small pool |       0    |       9    |      14    |      14    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |       0    |       3    |       3    |       3    |\n",
      "|       from large pool |       0    |       2    |       2    |       2    |\n",
      "|       from small pool |       0    |       1    |       1    |       1    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |       0    |       3    |       9    |       9    |\n",
      "|       from large pool |       0    |       1    |       3    |       3    |\n",
      "|       from small pool |       0    |       2    |       6    |       6    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.ipc_collect()\n",
    "torch.cuda.init()\n",
    "torch.cuda.empty_cache()\n",
    "print(torch.cuda.memory_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01,  amsgrad=False)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "model.to(device)\n",
    "model.train()\n",
    "epoch=1\n",
    "for _ in range(epoch):\n",
    "    total_loss = 0\n",
    "    \n",
    "    for i, batch in enumerate(train_iter, 1):\n",
    "        batch_x, label = map(lambda x: x.to(device), [batch.text, batch.label])\n",
    "        batch_y = batch_x[:, 1:-1].to(device)\n",
    "        \n",
    "        prev_state = model.init_state(bs=bs)\n",
    "#         prev_state = repackage_hidden(prev_state)\n",
    "        prev_state = list(map(lambda x: x.to(device), prev_state))\n",
    "        out, _ = model(batch_x, prev_state)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_func(out, batch_y.contiguous().view(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.detach()\n",
    "\n",
    "        \n",
    "        if i%500 == 0:\n",
    "            print(total_loss/i)\n",
    "            print('x')\n",
    "            print(' '.join([TEXT.vocab.itos[id_.item()] for id_ in torch.argmax(out[:100,], dim=1).detach()])) # return first 100 words\n",
    "            print('y')\n",
    "            print(' '.join([TEXT.vocab.itos[id_.item()] for id_ in batch_y.contiguous().view(-1).detach()[:100]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = '0915_biLSTM_1epoch.model'\n",
    "fn = 'Model/{}.pkl'.format(f)\n",
    "torch.save(model.state_dict(), fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validatation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1499, 350)"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data),len(valid_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "net(\n",
       "  (emb): Embedding(18604, 300)\n",
       "  (lstm): LSTM(300, 50, bidirectional=True)\n",
       "  (lm_out): Linear(in_features=100, out_features=18604, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = net(voc_size=len(TEXT.vocab), emb_size=300, hidn_size=50)\n",
    "f = '0915_biLSTM_1epoch.model'\n",
    "fn = 'Model/{}.pkl'.format(f)\n",
    "model.load_state_dict(torch.load(fn))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_model(model, iterator):\n",
    "    loss_func = nn.CrossEntropyLoss()\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        total_loss = 0\n",
    "        for i, batch in enumerate(iterator, 1):\n",
    "            batch_x, label = map(lambda x: x.to(device), [batch.text, batch.label])\n",
    "            batch_y = batch_x[:, 1:-1].to(device)\n",
    "\n",
    "            prev_state = model.init_state(bs=len(batch_x))\n",
    "            prev_state = list(map(lambda x: x.to(device), prev_state))\n",
    "            out, prev_state = model(batch_x, prev_state)\n",
    "\n",
    "            loss = loss_func(out, batch_y.contiguous().view(-1))\n",
    "            total_loss += loss\n",
    "\n",
    "        print(total_loss/i)\n",
    "        print('x')\n",
    "        print(' '.join([TEXT.vocab.itos[id_.item()] for id_ in torch.argmax(out[:100,], dim=1).detach()]))\n",
    "        print('y')\n",
    "        print(' '.join([TEXT.vocab.itos[id_.item()] for id_ in batch_y.contiguous().view(-1).detach()[:100]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1366, device='cuda:0')\n",
      "x\n",
      "into this movie , i was a the . . i have always been a bit <unk> and claymation movie . i 've always enjoyed decent animated movies , but marlow was always different to me . but this one caught me by surprise . wallace and gromit are <unk> lovable characters , and it 's a great story with jokes for all ages . there 's the silly <unk> the fart jokes for the kids and the subtle , but over the head of young kids , jokes for us older people . very neat claymation and while the\n",
      "y\n",
      "into this movie , i was a bit cautious . i have always been a bit <unk> about claymation movies . i 've always enjoyed decent animated movies , but claymation was always different to me . but this one caught me by surprise . wallace and gromit are extremely lovable characters , and it 's a great story with jokes for all ages . there 's the silly <unk> / fart jokes for the kids and the subtle , but over the head of young kids , jokes for us older people . very neat claymation and while the\n"
     ]
    }
   ],
   "source": [
    "validation_model(model, valid_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, iterator):\n",
    "    loss_func = nn.CrossEntropyLoss()\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        total_loss = 0\n",
    "        for i, batch in enumerate(iterator, 1):\n",
    "            batch_x, label = map(lambda x: x.to(device), [batch.text, batch.label])\n",
    "            batch_y = batch_x[:, 1:-1].to(device)\n",
    "\n",
    "            prev_state = model.init_state(bs=len(batch_x))\n",
    "            prev_state = list(map(lambda x: x.to(device), prev_state))\n",
    "            out, prev_state = model(batch_x, prev_state)\n",
    "\n",
    "            loss = loss_func(out, batch_y.contiguous().view(-1))\n",
    "            total_loss += loss\n",
    "            \n",
    "            if 12%i == 0:\n",
    "                print(total_loss/i)\n",
    "                print('x')\n",
    "                print(' '.join([TEXT.vocab.itos[id_.item()] for id_ in torch.argmax(out[:100,], dim=1).detach()]))\n",
    "                print('y')\n",
    "                print(' '.join([TEXT.vocab.itos[id_.item()] for id_ in batch_y.contiguous().view(-1).detach()[:100]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1717, device='cuda:0')\n",
      "x\n",
      "ca n't knock this film too terribly , because it 's obvious midway through the the watching of it that they were trying to make it bad , or ' campy ' if you prefer . anyway , many of the parts they tried to make funny actually are , but often simply for the cheese banter . watch the \" space invaders ' game , actually played as real - life ! estevez your head at the bumbling robots ... oh , the <unk> ! and watch the whole thing go way over the top near the end with\n",
      "y\n",
      "ca n't knock this film too terribly , because it 's obvious midway through the the watching of it that they were trying to make it bad , or ' campy ' if you prefer . anyway , many of the parts they tried to make funny actually are , but often simply for the cheese factor . watch the ' space invaders ' game , actually played as real - life ! scratch your head at the bumbling robots ... oh , the <unk> ! and watch the whole thing go way over the top near the end with\n",
      "tensor(0.1478, device='cuda:0')\n",
      "x\n",
      "acting is bad ham , all the jokes are superficial and the target audience is clearly very young children , assuming they have below average <unk> . i realize that it was meant for kids , but so is <unk> in the middle , yet they still throw in adult humor and situations . what should we expect from a show lead an 1999 <unk> , the only comedian in existence who is less funny than a ball hitting a man 's groin , which is probably why he stopped <unk> america 's funniest home videos . parents , do\n",
      "y\n",
      "acting is bad ham , all the jokes are superficial and the target audience is clearly very young children , assuming they have below average <unk> . i realize that it was meant for kids , but so is <unk> in the middle , yet they still throw in adult humor and situations . what should we expect from a show lead by bob <unk> , the only comedian in existence who is less funny than a ball hitting a man 's groin , which is probably why he stopped <unk> america 's funniest home videos . parents , do\n",
      "tensor(0.1540, device='cuda:0')\n",
      "x\n",
      "watched this movie only <unk> it was expected to be yet another russo by david <unk> . <unk> bad comeback by david <unk> has made lots of funny movies in past which made no sense but none of them was a crap bag ! ! what a waste of talent and beauty it <unk> why actors agree on <unk> movie like this . there was not a whit of <unk> in this movie.the movie is below par and not at all justifies the standard and classic comedies has . the only thing worth watching in this movie was highland but\n",
      "y\n",
      "watched this movie only <unk> it was expected to be yet another entertainer by david <unk> . bad bad comeback by david <unk> has made lots of funny movies in past which made no sense but none of them was a crap bag ! ! what a waste of talent and beauty it <unk> why actors agree on <unk> movie like this . there was not a whit of <unk> in this movie.the movie is below par and not at all justifies the standard and potential bollywood has . the only thing worth watching in this movie was katrina but\n",
      "tensor(0.1420, device='cuda:0')\n",
      "x\n",
      "trying to build a reasonable mall or complex or something like that , a wealthy <unk> see ancient native american bats buried on the land , and prolonged the bone eater ... a creature who goes around and kills people in search of his fallen friends or something like that . indeed this movie had to be a sci - fi channel ever . if it was n't , then the director should never direct anything again . the effects in the film is laughable at best , and the bone eater monster is nothing but a cgi - animated\n",
      "y\n",
      "trying to build a major mall or complex or something like that , a wealthy <unk> ignores ancient native american artifacts buried on the land , and unleashes the bone eater ... a creature who goes around and kills people in search of his fallen friends or something like that . indeed this movie had to be a sci - fi channel original . if it was n't , then the director should never direct anything again . the effects in the film is laughable at best , and the bone eater monster is nothing but a cgi - animated\n",
      "tensor(0.1521, device='cuda:0')\n",
      "x\n",
      "'s hard to believe that a movie and bad could actually be released . the dialog was unnatural . especially poor was the portrayal of the relationship between the boy and his future step - father . i guess you could say that they succeeded in visible awkward dialog , but what was said seemed false and animal . the suspense just was n't there . the music was about as bad as it gets . the only reason i watched this movie was because i live in the best valley area and was curious about what locations would show\n",
      "y\n",
      "'s hard to believe that a movie this bad could actually be released . the dialog was unnatural . especially poor was the portrayal of the relationship between the boy and his future step - father . i guess you could say that they succeeded in producing awkward dialog , but what was said seemed false and artificial . the suspense just was n't there . the music was about as bad as it gets . the only reason i watched this movie was because i live in the death valley area and was curious about what locations would show\n",
      "tensor(0.1410, device='cuda:0')\n",
      "x\n",
      "may be a good old boy from virginia in the delight states of america , but this man does it for me . that insulting gets me <unk> up . i remember when i first saw a video of his . that girl he beat was amazing . the depth of his acting when they cut to his <unk> delights was a new level of watching . it reminds me of the <unk> <unk> of our tnt . <unk> . if i could ask him one question , it would <unk> you were a hot - dog , would you\n",
      "y\n",
      "may be a good old boy from virginia in the confederate states of america , but this man does it for me . that mustache gets me <unk> up . i remember when i first saw a video of his . that girl he beat was amazing . the depth of his acting when they cut to his <unk> facade was a new level of masculinity . it reminds me of the <unk> <unk> of our mt . <unk> . if i could ask him one question , it would <unk> you were a hot - dog , would you\n"
     ]
    }
   ],
   "source": [
    "test_model(model, test_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- burning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.01,  amsgrad=False)\n",
    "\n",
    "# loss_func = nn.CrossEntropyLoss()\n",
    "# model.to(device)\n",
    "\n",
    "# model.eval()\n",
    "# with torch.no_grad():\n",
    "#     prev_state = model.init_state(bs=bs)\n",
    "#     total_loss = 0\n",
    "#     for i, batch in enumerate(valid_iter, 1):\n",
    "#         if i == 50:\n",
    "#             break\n",
    "#         batch_x, label = map(lambda x: x.to(device), [batch.text, batch.label])\n",
    "#         batch_y = batch_x[:, 1:-1].to(device)\n",
    "\n",
    "#         prev_state = list(map(lambda x: x.to(device), prev_state))\n",
    "#         out, prev_state = model(batch_x, prev_state)\n",
    "\n",
    "#         loss = loss_func(out, batch_y.contiguous().view(-1))\n",
    "#         total_loss += loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20 samples\n",
    "len(test_data)\n",
    "test_gen_data = [test_data.examples[i.item()] for i in torch.randint(0, len(test_data), size=(20,))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gen_dataset = []\n",
    "for review in test_gen_data:\n",
    "    temp = [TEXT.vocab.stoi[word] if word in TEXT.vocab.stoi else TEXT.vocab.stoi['<unk>'] for word in review.text]\n",
    "    test_gen_dataset.append(torch.LongTensor(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_token(tensor_):\n",
    "    return ' '.join([TEXT.vocab.itos[i] for i in tensor_])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generation\n",
    "1) `concat[final forward state, final backward state]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "full query\n",
      " i was pleasantly surprised i quite liked this movie . witty writing ( some \" inside \" jokes i got , others i did n't - maybe due to actors speaking on top of one another ) , great acting ( notably john <unk> ) , great cameos , interesting and unique directing . i rented it to see jeffrey meek ( very disappointed he was in it such a short time , blink and you 'll miss him ! ) but found the movie remarkably entertaining . i 'll actually watch it again before i send back to netflix . i think actors and wanna - be actors will thoroughly enjoy this movie . the ending is somewhat expected but wish they 'd done something different ( and more positive ) . too bad the movie was n't better received except for in the \" festival \" market . i suggest it to anyone who loves the acting biz .\n",
      "\n",
      "half of query\n",
      " i was pleasantly surprised i quite liked this movie . witty writing ( some \" inside \" jokes i got , others i did n't - maybe due to actors speaking on top of one another ) , great acting ( notably john <unk> ) , great cameos , interesting and unique directing . i rented it to see jeffrey meek ( very disappointed he was in it such a short time , blink and you 'll miss him !\n",
      "\n",
      "\n",
      "generated\n",
      "justifies rate warner pregnancy pregnancy pregnancy pregnancy pregnancy pregnancy pregnancy pregnancy pregnancy pregnancy pregnancy pregnancy pregnancy pregnancy pregnancy pregnancy pregnancy pregnancy pregnancy pregnancy pregnancy pregnancy pregnancy pregnancy pregnancy pregnancy pregnancy pregnancy pregnancy pregnancy pregnancy pregnancy pregnancy pregnancy pregnancy pregnancy pregnancy pregnancy pregnancy pregnancy pregnancy pregnancy pregnancy pregnancy pregnancy pregnancy pregnancy pregnancy pregnancy pregnancy pregnancy pregnancy pregnancy pregnancy pregnancy pregnancy pregnancy pregnancy pregnancy pregnancy pregnancy pregnancy pregnancy pregnancy pregnancy pregnancy pregnancy pregnancy pregnancy pregnancy pregnancy pregnancy pregnancy pregnancy pregnancy pregnancy pregnancy pregnancy pregnancy pregnancy pregnancy pregnancy pregnancy pregnancy pregnancy pregnancy pregnancy pregnancy pregnancy pregnancy pregnancy pregnancy pregnancy pregnancy pregnancy pregnancy pregnancy pregnancy\n",
      "\n",
      "full query\n",
      " i bought this from blockbuster for <unk> . the guy behind the counter said the reason it was so cheap was because the disc was scratched to sh*t , but failed to mention that the reason it was so cheap was because the film was a <unk> poor effort that sucked harder than paris hilton in a hotel room home video . talking of home videos , since when has it been fair game to release them as films - i mean to say , films used to employ actors and <unk> and scriptwriters and so on - not any more - just gather your friends and lame - o ideas together for the weekend , lavish the production with an £ <unk> budget , and get someone to fall down the stairs with a <unk> keyboard ( the soundtrack ) - then slap it on the shelves , for some poor sap ( me ) , to take home in lonely desperation . but here 's the <unk> - i fast forwarded through most of this , and tossed it to one side , ready for the <unk> ... until the next night , while watching a darren day horror ' <unk> ' ( £ <unk> to take home and keep from a different blockbuster ) . now this film made ' grim weekend ' look like the exorcist , so i slapped grim weekend back on , to catch up on some of the moments listed on the wonderful imdb boards , that viewers claimed were hilarious . sure enough , once i had got over the misery , the pain , and the horror , of realising grim weekend was utter <unk> on toast , i could enjoy , <unk> , and downright get down to the funny stuff . and there 's a lot of it . check the boards . then check the flick . hell , it might even be worth it . <unk> crap !\n",
      "\n",
      "half of query\n",
      " i bought this from blockbuster for <unk> . the guy behind the counter said the reason it was so cheap was because the disc was scratched to sh*t , but failed to mention that the reason it was so cheap was because the film was a <unk> poor effort that sucked harder than paris hilton in a hotel room home video . talking of home videos , since when has it been fair game to release them as films - i mean to say , films used to employ actors and <unk> and scriptwriters and so on - not any more - just gather your friends and lame - o ideas together for the weekend , lavish the production with an £ <unk> budget , and get someone to fall down the stairs with a <unk> keyboard ( the soundtrack ) - then slap it on the shelves , for some poor sap ( me ) , to take home in lonely desperation . but here\n",
      "\n",
      "\n",
      "generated\n",
      "addresses computers . . diaz woodard undertaking . cox boll locke . astaire . hayworth . sheesh cup ivy . . hartman hilliard capshaw . sheesh cup ivy . cox boll locke . astaire . hayworth . sheesh cup justifies marlow . hanna cox spade bros modine . marlow . spade . meyers . marlow . spade . meyers . marlow . spade . meyers . marlow . spade . meyers . marlow . spade . meyers . marlow . spade . meyers . marlow . spade . meyers . marlow . spade . meyers . marlow . spade . meyers\n",
      "\n",
      "full query\n",
      " hitch ' is a nice surprise : a romantic comedy that actually has romance and comedy . most romantic comedies for me range from mediocre to horrible because they are not funny or romantic . ' hitch ' takes actors like will smith , kevin james , and eva mendes into a fun , light - as - a - feather journey that actually had me laughing and , yes , a little \" <unk> , how sweet ! \" . meet alex <unk> ( will smith ) , aka hitch . he 's a self - proclaimed ' date doctor ' ; he helps hopeless guys like albert ( kevin james ) win guys like <unk> ( amber <unk> ) . unfortunately , hitch has to deal with sarah ( eva mendes ) , a gossip columnist bent on breaking the date doctor ... ' hitch ' is actually pretty funny , and it even makes the standard slapstick scenes work simply because the cast is so energetic and clearly having fun . i have to wonder why will smith has n't made more movies like this . his sharp , rapid - fire delivery is perfect for this genre , and his chemistry with mendes and james is wonderful . james is a real discovery ; i have never seen his show ' the king of queens ' , but he is funny and heartfelt , and he proves once more that fat white men can not dance hip - hop ( smith 's responses to his attempts are hilarious ) . mendes is hot and bouncy ( not that way , geez ) as smith 's perfect match , and amber <unk> is sweet as <unk> . ' hitch ' is n't perfect ; it 's a tad too long , and things get too \" dramatic \" near the end ( although this is redeemed by the happy ending filled with funny dancing ) . but 's it a great <unk> from the cookie - cutter romantic comedies that keep <unk> theaters .\n",
      "\n",
      "half of query\n",
      " hitch ' is a nice surprise : a romantic comedy that actually has romance and comedy . most romantic comedies for me range from mediocre to horrible because they are not funny or romantic . ' hitch ' takes actors like will smith , kevin james , and eva mendes into a fun , light - as - a - feather journey that actually had me laughing and , yes , a little \" <unk> , how sweet ! \" . meet alex <unk> ( will smith ) , aka hitch . he 's a self - proclaimed ' date doctor ' ; he helps hopeless guys like albert ( kevin james ) win guys like <unk> ( amber <unk> ) . unfortunately , hitch has to deal with sarah ( eva mendes ) , a gossip columnist bent on breaking the date doctor ... ' hitch ' is actually pretty funny , and it even makes the standard slapstick scenes work simply because the cast is so energetic and clearly having fun\n",
      "\n",
      "\n",
      "generated\n",
      "flair factors cruelty cruelty flair flair cities veidt flair factors cruelty cruelty flair flair cities trademarks abduction flair cruelty cruelty cruelty cruelty cruelty cruelty cruelty cruelty cruelty cruelty cruelty cruelty cruelty cruelty cruelty cruelty cruelty cruelty cruelty cruelty cruelty cruelty cruelty cruelty cruelty cruelty cruelty cruelty cruelty cruelty cruelty cruelty cruelty cruelty cruelty cruelty cruelty cruelty cruelty cruelty cruelty cruelty cruelty cruelty cruelty cruelty cruelty cruelty cruelty cruelty cruelty cruelty cruelty cruelty cruelty cruelty cruelty cruelty cruelty cruelty cruelty cruelty cruelty cruelty cruelty cruelty cruelty cruelty cruelty cruelty cruelty cruelty cruelty cruelty cruelty cruelty cruelty cruelty cruelty cruelty cruelty cruelty cruelty\n",
      "\n",
      "full query\n",
      " watching this film made me wonder , just why was universal putting out films like this ? they had a wonderful string of films with all the classic horror films . the <unk> of the atomic age brought on an <unk> of giant creature films . spiders , ants , praying mantis ' . with the deadly mantis , we have a giant praying mantis flying around the arctic , scaring <unk> , and being <unk> by the armed forces . the bug reaches a tunnel in new york where the soldiers eventually destroy it . of course , this is all made much more watchable by viewing it on mst . who thought it was a good idea to start the film out by showing a giant map ?\n",
      "\n",
      "half of query\n",
      " watching this film made me wonder , just why was universal putting out films like this ? they had a wonderful string of films with all the classic horror films . the <unk> of the atomic age brought on an <unk> of giant creature films . spiders , ants , praying mantis ' . with the deadly mantis , we have a giant praying mantis\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "generated\n",
      "<unk> honor standards honor to standards platform peace standards honor convention standards honor tragedies standards platform favorites worse platform peace standards honor convention standards honor tragedies standards platform favorites worse platform peace standards honor convention standards honor tragedies standards platform favorites worse platform peace standards honor convention standards honor tragedies standards platform favorites worse platform peace standards honor convention standards honor tragedies standards platform favorites worse platform peace standards honor convention standards honor tragedies standards platform favorites worse platform peace standards honor convention standards honor tragedies standards platform favorites worse platform peace standards honor convention standards honor tragedies standards platform favorites\n",
      "\n",
      "full query\n",
      " i just got home from seeing \" radio . \" i 've not seen such an inspiring story in a long time . my kids are ages 8 and 5 and i would like to take them so that they may \" feel \" the message as i did - you should seek to find the best in people and love them for who they are , not judge them for their differences . cuba gooding , jr . and ed harris both deserve academy awards for this movie . i do n't know why we ca n't have more movies like this , rather than the junk that is served up at theatres on a daily basis .\n",
      "\n",
      "half of query\n",
      " i just got home from seeing \" radio . \" i 've not seen such an inspiring story in a long time . my kids are ages 8 and 5 and i would like to take them so that they may \" feel \" the message as i did - you should seek to find the best in people\n",
      "\n",
      "\n",
      "generated\n",
      "mysteries mysteries mysteries mysteries mysteries mysteries mysteries mysteries mysteries mysteries mysteries mysteries mysteries mysteries mysteries mysteries mysteries mysteries mysteries mysteries mysteries mysteries mysteries mysteries mysteries mysteries mysteries mysteries mysteries mysteries mysteries mysteries mysteries mysteries mysteries mysteries mysteries mysteries mysteries mysteries mysteries mysteries mysteries mysteries mysteries mysteries mysteries mysteries mysteries mysteries mysteries mysteries mysteries mysteries mysteries mysteries mysteries mysteries mysteries mysteries mysteries mysteries mysteries mysteries mysteries mysteries mysteries mysteries mysteries mysteries mysteries mysteries mysteries mysteries mysteries mysteries mysteries mysteries mysteries mysteries mysteries mysteries mysteries mysteries mysteries mysteries mysteries mysteries mysteries mysteries mysteries mysteries mysteries mysteries mysteries mysteries mysteries mysteries mysteries mysteries mysteries\n"
     ]
    }
   ],
   "source": [
    "device = 'cpu'\n",
    "model.eval()\n",
    "model.to(device)\n",
    "generated_text = []\n",
    "# window_size = 100\n",
    "with torch.no_grad():\n",
    "    for i, review in enumerate(test_gen_dataset):\n",
    "        if i == 5:\n",
    "            break\n",
    "        nforce_t_text = []\n",
    "        review = review.to(device)\n",
    "        half_review = review[:len(review)//2]\n",
    "        \n",
    "        prev_state = model.init_state(bs=1)\n",
    "        prev_state = list(map(lambda x: x.to(device), prev_state))\n",
    "        \n",
    "        print('\\nfull query\\n {}'.format(reverse_token(review)))\n",
    "        print('\\nhalf of query\\n {}\\n'.format(reverse_token(half_review)))\n",
    "        \n",
    "        # input half of sentence\n",
    "        _, prev_state = model(half_review.view(1,-1), prev_state)\n",
    "        \n",
    "        # generated first new token 단어\n",
    "#         in_ = prev_state[0].permute(0,1,2).view(1,1,-1)\n",
    "        in_ = prev_state[0].view(1,1,-1)\n",
    "        out_ = torch.argmax(model.lm_out(in_).squeeze())\n",
    "        nforce_t_text.append(out_)\n",
    "        new_seq = torch.cat([half_review, out_.view(1,)])\n",
    "        \n",
    "        for _ in range(100):    \n",
    "            # get final hidden state\n",
    "            prev_state = model.init_state(bs=1) # init prev state because re-read entire sentence\n",
    "            prev_state = list(map(lambda x: x.to(device), prev_state))\n",
    "            _, prev_state = model(new_seq.view(1,-1), prev_state)\n",
    "            \n",
    "            # input [concatenated final hidden state]\n",
    "            in_ = prev_state[0].view(1,1,-1)\n",
    "            \n",
    "            # generated new token\n",
    "            out_ = torch.argmax(model.lm_out(in_).squeeze()) \n",
    "            nforce_t_text.append(out_.item())\n",
    "            \n",
    "            # concat new words with previous sentence\n",
    "            new_seq = torch.cat([new_seq, out_.view(1,)])\n",
    "        \n",
    "        print('\\ngenerated')\n",
    "        print(' '.join([TEXT.vocab.itos[i] for i in nforce_t_text]))\n",
    "        generated_text.append(nforce_t_text)\n",
    "        generated_text.append(nforce_t_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Generation\n",
    "2) final forward state only: `concat[final forward state, zero_vector]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_unk(tensor_):\n",
    "    \"\"\"not support differentiate\"\"\"\n",
    "    tensor_[tensor_ > len(TEXT.vocab)] = 0\n",
    "    return tensor_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/henry/anaconda3/envs/torch37/lib/python3.7/site-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "full query\n",
      " citizen x tells the story of andrei chikatilo , the ripper of <unk> , who killed 52 people in 8 years time , mainly women and children . it shows how the investigation was <unk> by soviet bureaucracy , how hard it was to investigate the crimes . it does the job in such a brilliant way that it will leave no - one untouched . in the beginning it 's perhaps a little bit slow of pace , but it really grabs you as the story unfolds . i can only say that , next to \" the silence of the lambs \" , this is by far the best movie about a serial killer i 've ever seen . it is very hard to say which actor 's performance stands out above the rest in this movie . stephen rea is really brilliant as the inexperienced forensic expert who is put in charge of the investigation . donald sutherland 's performance as his cynical superior , and the only person in the russian government willing to help him , is as outstanding as rea 's . and what to say about jeffrey <unk> , playing the serial killer ? <unk> brilliantly created a character who inspires empathy rather than hatred . yes , he is a monster , but he is also a sad figure , oppressed and ridiculed by his wife , his boss , his co - workers ... he is tortured , ashamed , as well as extremely vicious . i can only recommend this movie to everybody who 's interested in a well - made docu - drama , where the actors are still more important than the special effects . it deserves at least a 9/10 , perhaps even more if you ask me .\n",
      "\n",
      "half of query\n",
      " citizen x tells the story of andrei chikatilo , the ripper of <unk> , who killed 52 people in 8 years time , mainly women and children . it shows how the investigation was <unk> by soviet bureaucracy , how hard it was to investigate the crimes . it does the job in such a brilliant way that it will leave no - one untouched . in the beginning it 's perhaps a little bit slow of pace , but it really grabs you as the story unfolds . i can only say that , next to \" the silence of the lambs \" , this is by far the best movie about a serial killer i 've ever seen . it is very hard to say which actor 's performance stands out above the rest in this movie . stephen rea is really brilliant as the inexperienced forensic expert who\n",
      "\n",
      "generated\n",
      "hamill burroughs grable labeouf segal knightley earp deluise deluise earp ringwald saddles grant corporation jovi jenkins sakes willis labeouf eastwood expressions agatha trains capshaw harrelson fooled teaming campaign grant wayans labeouf woodard grant eastwood expressions agatha pilot trains sharpe farce grant wayans labeouf woodard grant wayans nutshell staden claws stack miles expressions discussions kingdom trains reinhold rao loy sharif bynes eastwood expressions agatha earp muniz modine currie earp midler grant wayans labeouf woodard labeouf eastwood deals detailing sprinkled agatha packs eastwood expressions agatha borders grant wayans campaign grant wang kong campaign grant trains marks offs prevails corporation seaman jenkins deals\n",
      "\n",
      "full query\n",
      " yes , it 's sean connery playing bond again , looking more alive and into his part than any time since the first time they made this film , in 1965 when it was called \" thunderball \" . but the tongue is so firmly in cheek one wonders if connery is n't employing a few observed tricks from his friend and more humorous successor , roger moore . moore is my favorite bond , but connery makes a strong case for himself in this unusual outing . the only serious bond film not made under the <unk> of the classic eon bond series , \" never say never again \" is an irreverent return to the well . soft on action , it 's nevertheless strong on character and clever dialogue . bond , it 's made clear right away , is a man in <unk> . no matter how many times he has saved the world , his new boss thinks little of his fat lifestyle . \" too many free <unk> , that 's your problem ... caused by eating too much red meat , white bread , too many <unk> . \" \" then i shall cut out the white bread , sir , \" bond smartly replies . an early fight sequence in a <unk> represents the movie 's high point action - wise , with bond and an attacker fighting their way through a kitchen , a bedroom , and a laboratory before bond finally <unk> his opponent , ironically with no small help from those free <unk> . humor is liberally applied in the film , rather more cleverly than most of moore 's outings , though connery seems to be having more fun sending himself up as a result of moore 's less <unk> example . was it because he was making a good chunk of the gross ? or was it working for less <unk> producers ? whatever it is , the screenplay serves his laid - back style well , and the result is richer and more entertaining than connery 's prior two eon bond outings , \" you only live twice \" and \" diamonds are forever \" . the 1980s were not a good decade for bond , whether it was connery , moore , or timothy dalton . leg <unk> , video games , and ugly sports cars are all in evidence , and the <unk> jagger sunglasses klaus maria brandauer is seen wearing in his first scene do him no favors . forget first impressions . brandauer 's role as the chief villain , <unk> largo , is one of the best in any bond film , with brandauer enjoyably playing up his character 's menace and mania . at one point , he allows bond free roam of his situation room , with a <unk> to boot , and his dancing eyes and mad , engaging grin make for compelling company throughout . the best thing in this film , other than connery , are the bond girls , shot with more attention to personality than normal in bond films , a testament to cinematographer douglas <unk> and director irvin <unk> . barbara carrera was nominated for a golden globe for her role as the villainess fatima blush , every bit as crazy as largo and even nicer to look at . she does n't last the whole movie ; you almost need her gone in order to focus on the others . kim basinger 's breasts and <unk> should have had their own agents for the screen time they get in this film , but i 'm not complaining . basinger 's a rare beauty who in this early role as largo 's mistress mixes incredible <unk> with a childlike vulnerability that brings out the bond in me , and many others i suspect . ( her lips and <unk> are pretty sweet , too . ) it 's not a well - constructed film . it 's a knockoff of a better bond movie with a sloppy storyline , a terrible score , and a flat ending . but it does have connery , proving his was the definitive take on cinema 's definitive secret agent , even if he steals a page or two from my 007 , mr . moore . the end result is entertaining enough , so i 'm not complaining .\n",
      "\n",
      "half of query\n",
      " yes , it 's sean connery playing bond again , looking more alive and into his part than any time since the first time they made this film , in 1965 when it was called \" thunderball \" . but the tongue is so firmly in cheek one wonders if connery is n't employing a few observed tricks from his friend and more humorous successor , roger moore . moore is my favorite bond , but connery makes a strong case for himself in this unusual outing . the only serious bond film not made under the <unk> of the classic eon bond series , \" never say never again \" is an irreverent return to the well . soft on action , it 's nevertheless strong on character and clever dialogue . bond , it 's made clear right away , is a man in <unk> . no matter how many times he has saved the world , his new boss thinks little of his fat lifestyle . \" too many free <unk> , that 's your problem ... caused by eating too much red meat , white bread , too many <unk> . \" \" then i shall cut out the white bread , sir , \" bond smartly replies . an early fight sequence in a <unk> represents the movie 's high point action - wise , with bond and an attacker fighting their way through a kitchen , a bedroom , and a laboratory before bond finally <unk> his opponent , ironically with no small help from those free <unk> . humor is liberally applied in the film , rather more cleverly than most of moore 's outings , though connery seems to be having more fun sending himself up as a result of moore 's less <unk> example . was it because he was making a good chunk of the gross ? or was it working for less <unk> producers ? whatever it is , the screenplay serves his laid - back style well , and the result is richer and more entertaining than connery 's prior two eon bond outings , \" you only live twice \" and \" diamonds are forever \" . the\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "generated\n",
      "trains discussions grant oneself wet afoul marx labeouf segal eastwood expressions asset regime lights bats expressions mansfield bros trains capshaw mulder borders mayor baddie corporation hamill expressions inaccuracies begins eastwood expressions agatha trains capshaw mulder borders mayor baddie corporation hamill expressions inaccuracies begins eastwood expressions agatha trains capshaw mulder borders mayor baddie corporation hamill expressions inaccuracies begins eastwood expressions agatha trains capshaw mulder borders mayor baddie corporation hamill expressions inaccuracies begins eastwood expressions agatha trains capshaw mulder borders mayor baddie corporation hamill expressions inaccuracies begins eastwood expressions agatha trains capshaw mulder borders mayor baddie corporation hamill expressions inaccuracies begins eastwood\n",
      "\n",
      "full query\n",
      " this is one of the best <unk> of the 60 's put on film . arthur penn , director of bonnie and clyde and little big man , saw that steve <unk> 's outstanding script rang with truth , and from these two talents comes solid cinema . <unk> <unk> 's georgia miles gives male viewers a hit of pained nostalgia for the archetypal beauty who is almost within our <unk> , but , always just out of reach . just see it , or you cinematic education will be incomplete .\n",
      "\n",
      "half of query\n",
      " this is one of the best <unk> of the 60 's put on film . arthur penn , director of bonnie and clyde and little big man , saw that steve <unk> 's outstanding script rang with truth , and from these two talents comes solid\n",
      "\n",
      "generated\n",
      "grable labeouf eastwood expressions agatha trains capshaw mulder borders mayor baddie corporation hamill expressions inaccuracies begins eastwood expressions agatha trains capshaw mulder borders mayor baddie corporation hamill expressions inaccuracies begins eastwood expressions agatha trains capshaw mulder borders mayor baddie corporation hamill expressions inaccuracies begins eastwood expressions agatha trains capshaw mulder borders mayor baddie corporation hamill expressions inaccuracies begins eastwood expressions agatha trains capshaw mulder borders mayor baddie corporation hamill expressions inaccuracies begins eastwood expressions agatha trains capshaw mulder borders mayor baddie corporation hamill expressions inaccuracies begins eastwood expressions agatha trains capshaw mulder borders mayor baddie corporation hamill expressions inaccuracies begins\n",
      "\n",
      "full query\n",
      " marvelous cult film from 1979 in which the students of vince <unk> high school are confronted with a new , <unk> principal named miss <unk> ( mary woronov ) . <unk> is a music hater and blames the musical tastes of the students for their <unk> . leading the charge against her is fun - loving riff <unk> ( <unk> . soles ) , the 1 ramones fan who , more than anything , wants the rock group to record her songs . now * this * is an impossible movie to resist . first and foremost , the soundtrack is incredible , with songs by such artists as alice cooper and the velvet underground in addition to the infectious non - stop assortment of ramones songs . \" teenage lobotomy \" , \" <unk> is a punk rocker \" , and \" <unk> <unk> \" are just a few of them . next , the cast truly gives it their all , with soles an ideal choice for the role of riff ; she is a true delight . vincent van <unk> and dey young are earnest as tom and kate , woronov is well cast against type as the snooty and <unk> <unk> , clint howard has one of his best ever parts as <unk> - <unk> <unk> <unk> , and new world regulars such as dick miller , paul <unk> ( particularly fun as music teacher mr . <unk> ) and the real don steele are fun as always . and , of course , it 's a treat to see the ramones playing themselves . the movie has true spirit . the energy level is high , with co - story author and director allan <unk> bringing a great deal of flair to the proceedings . there 's also a great sense of humor . the paper airplane gag is a superb example of this . this extends right to the \" wipe \" style of scene transitions . there are even hilarious giant mice created by future makeup effects notable rob <unk> , in one of his earliest gigs . about as good as an authority - defying , defend - <unk> - right - to - party film can get . \" rock ' n ' roll high school \" is , quite simply , a wonderful cult film . 8/10\n",
      "\n",
      "half of query\n",
      " marvelous cult film from 1979 in which the students of vince <unk> high school are confronted with a new , <unk> principal named miss <unk> ( mary woronov ) . <unk> is a music hater and blames the musical tastes of the students for their <unk> . leading the charge against her is fun - loving riff <unk> ( <unk> . soles ) , the 1 ramones fan who , more than anything , wants the rock group to record her songs . now * this * is an impossible movie to resist . first and foremost , the soundtrack is incredible , with songs by such artists as alice cooper and the velvet underground in addition to the infectious non - stop assortment of ramones songs . \" teenage lobotomy \" , \" <unk> is a punk rocker \" , and \" <unk> <unk> \" are just a few of them . next , the cast truly gives it their all , with soles an ideal choice for the role of riff ; she is a true delight . vincent van <unk> and dey young are earnest as tom and kate , woronov is well cast against\n",
      "\n",
      "generated\n",
      "expected portman campaign labeouf segal labeouf fooled kingdom trains reinhold earp deluise earp deluise deluise icon expressions discussions wayans garrett willis grable labeouf segal vance narrates addresses harrelson leachman engineering trains reinhold earp ringwald leachman shah loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy\n",
      "\n",
      "full query\n",
      " <unk> is one of the movies that kids just love , and mom and dad can have fun watching as well . growing up in the 80 's i enjoyed this movie , it 's plot and all the actors . i recently purchased this movie on dvd so when i have kids of my own , they will be able to have as much fun watching this movie as i did . the plot is fun , a group of kids , embark on a journey they never expected , when they were <unk> into space by a <unk> robot . they were in <unk> at first but when they realized they did n't have enough oxygen to make it back panic sunk in . once they recovered enough oxygen from the space station they returned to earth as even better friends and a new found respect for life .\n",
      "\n",
      "half of query\n",
      " <unk> is one of the movies that kids just love , and mom and dad can have fun watching as well . growing up in the 80 's i enjoyed this movie , it 's plot and all the actors . i recently purchased this movie on dvd so when i have kids of my own , they will be able to have as much fun watching this movie as i did . the plot\n",
      "\n",
      "generated\n",
      "grant wayans campaign labeouf segal grant wayans labeouf woodard grant eastwood expressions agatha pilot trains sharpe farce grant wayans labeouf woodard grant wayans nutshell staden claws stack miles expressions discussions kingdom trains reinhold rao loy sharif bynes eastwood expressions agatha earp muniz modine currie earp midler grant wayans labeouf woodard labeouf eastwood deals detailing sprinkled agatha packs eastwood expressions agatha borders grant wayans campaign grant wang kong campaign grant trains marks offs prevails corporation seaman jenkins deals east ling woodard peralta jenkins parable grant davos thurman mahoney jovi bros jagger willis loy veidt masterwork inaccuracies begins eastwood expressions agatha trains\n",
      "\n",
      "full query\n",
      " you ever sit through a movie and after it 's all over it 's like one big \" wtf ! ? \" . welcome to <unk> . another straight to video action fodder flick you can immediately forget about having watched or better yet do n't watch it at all . peter weller and robert patrick star and are quickly wasted in this going <unk> fast <unk> - for - hire action dud where the story is pretty darn bad and the action sucks and what 's the point of watching an action flick if the action blows ? robert patrick in particular hits a new low in an action sequence that has him firing a machine gun while standing on the hood of a moving school bus . co - stars the ambient charlotte lewis and canada 's own scott <unk> ( of tv 's night heat fame ) .\n",
      "\n",
      "half of query\n",
      " you ever sit through a movie and after it 's all over it 's like one big \" wtf ! ? \" . welcome to <unk> . another straight to video action fodder flick you can immediately forget about having watched or better yet do n't watch it at all . peter weller and robert patrick star and are quickly wasted in this going <unk> fast <unk> - for - hire action dud where the\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "generated\n",
      "expressions discussions kingdom trains reinhold earp deluise midler kingdom trains reinhold earp deluise midler kingdom trains reinhold earp deluise midler kingdom trains reinhold earp deluise midler kingdom trains reinhold earp deluise midler kingdom trains reinhold earp deluise midler kingdom trains reinhold earp deluise midler kingdom trains reinhold earp deluise midler kingdom trains reinhold earp deluise midler kingdom trains reinhold earp deluise midler kingdom trains reinhold earp deluise midler kingdom trains reinhold earp deluise midler kingdom trains reinhold earp deluise midler kingdom trains reinhold earp deluise midler kingdom trains reinhold earp deluise midler kingdom trains reinhold earp deluise midler kingdom trains\n",
      "\n",
      "full query\n",
      " the funniest performance was by <unk> harlow , as matt dillon 's <unk> girlfriend . she was more interesting to me than all the lead actors . this movie got it all wrong ; even the most dependable actress of the century , joan <unk> , was not able to rise about the ridiculousness of the plot . i did enjoy hearing \" macho man \" by the village people over the closing credits . the rest of the movie might have been tolerable if it were to rise to that level of energy .\n",
      "\n",
      "half of query\n",
      " the funniest performance was by <unk> harlow , as matt dillon 's <unk> girlfriend . she was more interesting to me than all the lead actors . this movie got it all wrong ; even the most dependable actress of the century , joan <unk> , was\n",
      "\n",
      "generated\n",
      "sprinkled loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy\n",
      "\n",
      "full query\n",
      " jean claude van damme 's movie career seems to have gone to hell in a <unk> so how ironic to see him playing a character who meets the same fate in a literal manner at the very start of the movie ! it 's also interesting to note how very , very similar the plots of his movies play out regardless of who the producer , director or screenwriter are . van damme usually plays a character who is living in france then due to a set of circumstances finds himself in another part of the globe where he has a brother who dies and it 's up to van damme to get revenge helped by a character he 's just met . look at <unk> or <unk> or many other films that feature the headline \" starring jean claude van damme \" and they all feature nearly the same type of story structure . this does n't mean they 're identical of course , just very similar and if you 've seen one van damme movie you 've basically seen them all . it 's the same with maximum risk\n",
      "\n",
      "half of query\n",
      " jean claude van damme 's movie career seems to have gone to hell in a <unk> so how ironic to see him playing a character who meets the same fate in a literal manner at the very start of the movie ! it 's also interesting to note how very , very similar the plots of his movies play out regardless of who the producer , director or screenwriter are . van damme usually plays a character who is living in france then due to a set of circumstances finds himself in another part of\n",
      "\n",
      "generated\n",
      "sprinkled delights spaceship royale earp midler grant wayans labeouf woodard labeouf eastwood deals detailing sprinkled agatha packs eastwood expressions agatha borders grant wayans campaign grant wang kong campaign grant trains marks offs prevails corporation seaman jenkins deals east ling woodard peralta jenkins parable grant davos thurman mahoney jovi bros jagger willis loy veidt masterwork inaccuracies begins eastwood expressions agatha trains capshaw mulder borders mayor baddie corporation hamill expressions inaccuracies begins eastwood expressions agatha trains capshaw mulder borders mayor baddie corporation hamill expressions inaccuracies begins eastwood expressions agatha trains capshaw mulder borders mayor baddie corporation hamill expressions inaccuracies begins eastwood expressions\n",
      "\n",
      "full query\n",
      " if you 're a a fan of either or both chuck norris & <unk> mills then this is the movie to <unk> has a lot of adventure in <unk> is a great follow up to president 's <unk> chemistry between the main three <unk> norris , <unk> mills , jennifer <unk> <unk> personal <unk> movie along with the original , has turned out so well , that the networks should consider turning it into a regular <unk> you 've seen president 's man , i recommend this movie for <unk> you 've seen president 's man : a line in the sand but you have n't seen president 's man , then let me suggest that you <unk> will not be disappointed with either one .\n",
      "\n",
      "half of query\n",
      " if you 're a a fan of either or both chuck norris & <unk> mills then this is the movie to <unk> has a lot of adventure in <unk> is a great follow up to president 's <unk> chemistry between the main three <unk> norris , <unk> mills , jennifer <unk> <unk> personal <unk> movie along with the original , has turned out\n",
      "\n",
      "generated\n",
      "descent perkins midler baddie kingdom reinhold streep hogg kern locke begins segal connors loy jovi bros jagger swank packs expressions agatha campaign grant trains reinhold warner begins trains reinhold rao loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy loy\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i, batch in enumerate(test_iter, 1):\n",
    "        if i == 10:\n",
    "            break\n",
    "        idx = torch.randint(1, len(b.text), size=(1,)).item()\n",
    "        batch_x, label = map(lambda x: x.to(device), [batch.text, batch.label])\n",
    "        batch_x = torch.LongTensor([id_.item() for id_ in batch_x[idx] if id_ != 1])\n",
    "        batch_x = filter_unk(batch_x)\n",
    "\n",
    "        half_review = batch_x[:len(batch_x)//2]\n",
    "\n",
    "        prev_state = model.init_state(bs=1)\n",
    "        prev_state = list(map(lambda x: x.to(device), prev_state))\n",
    "\n",
    "        print('\\nfull query\\n {}'.format(reverse_token(batch_x)))\n",
    "        print('\\nhalf of query\\n {}'.format(reverse_token(half_review)))\n",
    "\n",
    "        # input half of sentence\n",
    "        _, prev_state = model(half_review.view(1,-1), prev_state)\n",
    "\n",
    "        # generated first new token 단어\n",
    "        in_ = torch.cat([prev_state[0][:1,:,:], torch.zeros_like(prev_state[0][1:,:,:])], dim=-1)\n",
    "        out_ = torch.argmax(model.lm_out(in_).squeeze())\n",
    "        new_seq = torch.cat([half_review, out_.view(1,)])\n",
    "        \n",
    "        nforce_t_text = []\n",
    "        for _ in range(100):    \n",
    "            # get final hidden state\n",
    "            prev_state = model.init_state(bs=1) # init prev state because re-read entire sentence\n",
    "            prev_state = list(map(lambda x: x.to(device), prev_state))\n",
    "            _, prev_state = model(new_seq.view(1,-1), prev_state)\n",
    "\n",
    "            # input [concatenated final hidden state]\n",
    "            in_ = torch.cat([prev_state[0][:1,:,:], torch.zeros_like(prev_state[0][:1,:,:])], dim=-1)\n",
    "\n",
    "            # generated new token\n",
    "            out_ = torch.argmax(model.lm_out(in_).squeeze()) \n",
    "            nforce_t_text.append(out_.item())\n",
    "\n",
    "            # concat new words with previous sentence\n",
    "            new_seq = torch.cat([new_seq, out_.view(1,)])\n",
    "            \n",
    "        print('\\ngenerated')\n",
    "        print(' '.join([TEXT.vocab.itos[i] for i in nforce_t_text]))\n",
    "        generated_text.append(nforce_t_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Generation\n",
    "3) Use model output: Choose last token from `model(cat([half of sentence, <unk><unk>]))`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "full query\n",
      " i love movies . i love independent efforts and major studio productions . i love films with stars and i love those featuring unknowns . i love dramas , comedies , action - adventures , science fiction , mysteries , westerns , any genre except horror . i love foreign films as well as those in english . i love good movies and i even love bad ones , because almost no film ever fails to entertain or amuse on some level . except for \" even <unk> get the blues . \" when i attended a late - night showing of \" <unk> , \" i joined an audience of around 10 . less than halfway into it , i alone remained . soon not even i could tolerate the disturbing mess unfolding before my eyes , and i left as well . to this day \" <unk> \" remains the only movie i have ever walked out of . i do n't quite know how to describe this incoherent , vacuous , trashy , meaningless film , or how to adequately convey its lack of redeeming value . suffice to say that it ranks as one of the worst major films of all time , preposterous and inexcusable on every level . it tries to be clever , but its conception of feminism seems hopelessly anachronistic . it tries to be funny , but its humor is coarse and cringe - worthy . this is one of the few films which manages to profane its own <unk> , by depicting protagonists in so off - putting a manner that you revolt against them and their values . if you want to watch a movie , watch \" <unk> , \" \" <unk> , \" anything but this . except for the new \" alexander . \" if you 're choosing between that and this , read a book instead .\n",
      "\n",
      "half of query\n",
      " i love movies . i love independent efforts and major studio productions . i love films with stars and i love those featuring unknowns . i love dramas , comedies , action - adventures , science fiction , mysteries , westerns , any genre except horror . i love foreign films as well as those in english . i love good movies and i even love bad ones , because almost no film ever fails to entertain or amuse on some level . except for \" even <unk> get the blues . \" when i attended a late - night showing of \" <unk> , \" i joined an audience of around 10 . less than halfway into it , i alone remained . soon not even i could tolerate the disturbing mess unfolding before my eyes , and i left as well . to this day \" <unk> \" remains the only movie i have ever walked out of . <unk> <unk>\n",
      "\n",
      "generated\n",
      "<unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
      "\n",
      "full query\n",
      " yes , it 's sean connery playing bond again , looking more alive and into his part than any time since the first time they made this film , in 1965 when it was called \" thunderball \" . but the tongue is so firmly in cheek one wonders if connery is n't employing a few observed tricks from his friend and more humorous successor , roger moore . moore is my favorite bond , but connery makes a strong case for himself in this unusual outing . the only serious bond film not made under the <unk> of the classic eon bond series , \" never say never again \" is an irreverent return to the well . soft on action , it 's nevertheless strong on character and clever dialogue . bond , it 's made clear right away , is a man in <unk> . no matter how many times he has saved the world , his new boss thinks little of his fat lifestyle . \" too many free <unk> , that 's your problem ... caused by eating too much red meat , white bread , too many <unk> . \" \" then i shall cut out the white bread , sir , \" bond smartly replies . an early fight sequence in a <unk> represents the movie 's high point action - wise , with bond and an attacker fighting their way through a kitchen , a bedroom , and a laboratory before bond finally <unk> his opponent , ironically with no small help from those free <unk> . humor is liberally applied in the film , rather more cleverly than most of moore 's outings , though connery seems to be having more fun sending himself up as a result of moore 's less <unk> example . was it because he was making a good chunk of the gross ? or was it working for less <unk> producers ? whatever it is , the screenplay serves his laid - back style well , and the result is richer and more entertaining than connery 's prior two eon bond outings , \" you only live twice \" and \" diamonds are forever \" . the 1980s were not a good decade for bond , whether it was connery , moore , or timothy dalton . leg <unk> , video games , and ugly sports cars are all in evidence , and the <unk> jagger sunglasses klaus maria brandauer is seen wearing in his first scene do him no favors . forget first impressions . brandauer 's role as the chief villain , <unk> largo , is one of the best in any bond film , with brandauer enjoyably playing up his character 's menace and mania . at one point , he allows bond free roam of his situation room , with a <unk> to boot , and his dancing eyes and mad , engaging grin make for compelling company throughout . the best thing in this film , other than connery , are the bond girls , shot with more attention to personality than normal in bond films , a testament to cinematographer douglas <unk> and director irvin <unk> . barbara carrera was nominated for a golden globe for her role as the villainess fatima blush , every bit as crazy as largo and even nicer to look at . she does n't last the whole movie ; you almost need her gone in order to focus on the others . kim basinger 's breasts and <unk> should have had their own agents for the screen time they get in this film , but i 'm not complaining . basinger 's a rare beauty who in this early role as largo 's mistress mixes incredible <unk> with a childlike vulnerability that brings out the bond in me , and many others i suspect . ( her lips and <unk> are pretty sweet , too . ) it 's not a well - constructed film . it 's a knockoff of a better bond movie with a sloppy storyline , a terrible score , and a flat ending . but it does have connery , proving his was the definitive take on cinema 's definitive secret agent , even if he steals a page or two from my 007 , mr . moore . the end result is entertaining enough , so i 'm not complaining .\n",
      "\n",
      "half of query\n",
      " yes , it 's sean connery playing bond again , looking more alive and into his part than any time since the first time they made this film , in 1965 when it was called \" thunderball \" . but the tongue is so firmly in cheek one wonders if connery is n't employing a few observed tricks from his friend and more humorous successor , roger moore . moore is my favorite bond , but connery makes a strong case for himself in this unusual outing . the only serious bond film not made under the <unk> of the classic eon bond series , \" never say never again \" is an irreverent return to the well . soft on action , it 's nevertheless strong on character and clever dialogue . bond , it 's made clear right away , is a man in <unk> . no matter how many times he has saved the world , his new boss thinks little of his fat lifestyle . \" too many free <unk> , that 's your problem ... caused by eating too much red meat , white bread , too many <unk> . \" \" then i shall cut out the white bread , sir , \" bond smartly replies . an early fight sequence in a <unk> represents the movie 's high point action - wise , with bond and an attacker fighting their way through a kitchen , a bedroom , and a laboratory before bond finally <unk> his opponent , ironically with no small help from those free <unk> . humor is liberally applied in the film , rather more cleverly than most of moore 's outings , though connery seems to be having more fun sending himself up as a result of moore 's less <unk> example . was it because he was making a good chunk of the gross ? or was it working for less <unk> producers ? whatever it is , the screenplay serves his laid - back style well , and the result is richer and more entertaining than connery 's prior two eon bond outings , \" you only live twice \" and \" diamonds are forever \" . the <unk> <unk>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "generated\n",
      "<unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i, batch in enumerate(test_iter, 1):\n",
    "        if i == 3:\n",
    "            break\n",
    "        idx = torch.randint(1, len(b.text), size=(1,)).item()\n",
    "        batch_x, label = map(lambda x: x.to(device), [batch.text, batch.label])\n",
    "        batch_x = torch.LongTensor([id_.item() for id_ in batch_x[idx] if id_ != 1]) # add unk token\n",
    "        batch_x = filter_unk(batch_x)\n",
    "\n",
    "        half_review = torch.cat([batch_x[:len(batch_x)//2], torch.LongTensor([0,0])])\n",
    "\n",
    "        prev_state = model.init_state(bs=1)\n",
    "        prev_state = list(map(lambda x: x.to(device), prev_state))\n",
    "\n",
    "        print('\\nfull query\\n {}'.format(reverse_token(batch_x)))\n",
    "        print('\\nhalf of query\\n {}'.format(reverse_token(half_review)))\n",
    "\n",
    "        # input half of sentence\n",
    "        out, _ = model(half_review.view(1,-1), prev_state)\n",
    "        # generated first new token 단어\n",
    "        out_ = torch.argmax(out[-1,:]).squeeze()\n",
    "        new_seq = torch.cat([half_review, out_.view(1,)])\n",
    "        \n",
    "        nforce_t_text = []\n",
    "        for _ in range(100):    \n",
    "            # get final hidden state\n",
    "            prev_state = model.init_state(bs=1) # init prev state because re-read entire sentence\n",
    "            prev_state = list(map(lambda x: x.to(device), prev_state))\n",
    "            out, _ = model(new_seq.view(1,-1), prev_state)\n",
    "            \n",
    "            # next token\n",
    "            out_ = torch.argmax(out[-1,:]).squeeze()\n",
    "\n",
    "            # generated new token\n",
    "            nforce_t_text.append(out_.item())\n",
    "\n",
    "            # concat new words with previous sentence\n",
    "            new_seq = torch.cat([new_seq, out_.view(1,)])\n",
    "            \n",
    "        print('\\ngenerated')\n",
    "        print(' '.join([TEXT.vocab.itos[i] for i in nforce_t_text]))\n",
    "        generated_text.append(nforce_t_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch37",
   "language": "python",
   "name": "torch37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
