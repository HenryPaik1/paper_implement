{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prerequisite\n",
    "- preprocessed IMDB dataset\n",
    "    - IMDB dataset oroginal: http://ai.stanford.edu/~amaas/data/sentiment/\n",
    "    - IMBD dataset csv: https://www.kaggle.com/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews\n",
    "- glove pretrained model: https://nlp.stanford.edu/projects/glove/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from torchtext import data\n",
    "from torchtext.data import TabularDataset\n",
    "import torchtext.vocab as vocab\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import logging\n",
    "import time\n",
    "import gc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/henry/anaconda3/envs/torch37/lib/python3.7/site-packages/torchtext/data/field.py:150: UserWarning: Field class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
      "/home/henry/anaconda3/envs/torch37/lib/python3.7/site-packages/torchtext/data/example.py:13: UserWarning: Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.', UserWarning)\n"
     ]
    }
   ],
   "source": [
    "PATH = '/home/henry/devdir'\n",
    "\n",
    "TEXT = data.Field(sequential=True,\n",
    "                  use_vocab=True,\n",
    "                  tokenize=str.split,\n",
    "                  lower=True,\n",
    "                  batch_first=True,\n",
    "                  fix_length=3014)\n",
    "\n",
    "LABEL = data.Field(sequential=False,\n",
    "                   use_vocab=False,\n",
    "                   batch_first=False,\n",
    "                   preprocessing = lambda x: int(x),\n",
    "                   is_target=True)\n",
    "\n",
    "# train_data, validation_data = TabularDataset.splits(\n",
    "#     path='.', \n",
    "#     train='./Data/IMDB_clean_train.json', \n",
    "#     test='./Data/IMDB_clean_validation.json', \n",
    "#     format='json',\n",
    "#     fields={'review': ('text', TEXT),\n",
    "#             'sentiment': ('label', LABEL)}, skip_header=True)\n",
    "\n",
    "dataset = TabularDataset(\n",
    "                path=PATH + '/Research_mine_codes/Data/IMDB_clean_data_with_eos.json',\n",
    "                skip_header=True,\n",
    "                format='json',\n",
    "                fields={'review': ('text', TEXT),\n",
    "                        'sentiment': ('label', LABEL)})\n",
    "\n",
    "# dataset = TabularDataset(\n",
    "#                 path=PATH + '/mine_codes/Data/IMDB_clean_sentence.json',\n",
    "#                 skip_header=True,\n",
    "#                 format='json',\n",
    "#                 fields={'review': ('text', TEXT),\n",
    "#                         'sentiment': ('label', LABEL)})\n",
    "\n",
    "\n",
    "FILE = PATH + '/data/glove.840B.300d.txt'\n",
    "TEXT.build_vocab(dataset, vectors=vocab.Vectors(name=FILE,), min_freq=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- test code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/henry/anaconda3/envs/torch37/lib/python3.7/site-packages/torchtext/data/iterator.py:48: UserWarning: BucketIterator class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
      "The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.\n"
     ]
    }
   ],
   "source": [
    "bs=3\n",
    "data_iter= data.BucketIterator(dataset,\n",
    "                    batch_size=bs,\n",
    "                    device=-1, sort_key=lambda x: len(x.text), sort=False, \n",
    "                    shuffle=True, repeat=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/henry/anaconda3/envs/torch37/lib/python3.7/site-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 3014]), torch.Size([3]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test\n",
    "b = next(iter(data_iter))\n",
    "b.text.shape, b.label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    3,    14,  1443,  ...,     1,     1,     1],\n",
       "        [    3,   613,  4288,  ...,     1,     1,     1],\n",
       "        [    3,    44, 11501,  ...,     1,     1,     1]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- special token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT.vocab.stoi['<unk>'], TEXT.vocab.stoi['<pad>']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_logger(name):\n",
    "    \n",
    "    # init\n",
    "    logger = logging.getLogger(name)\n",
    "    logger.setLevel(logging.INFO)\n",
    "    formatter = logging.Formatter\\\n",
    "        ('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "    formatter = logging.Formatter(\n",
    "        fmt='%(asctime)s.%(msecs)03d %(levelname)s:\\t%(message)s', datefmt='%Y-%m-%d %H:%M:%S'\n",
    "    )\n",
    "    \n",
    "#     # handler: console\n",
    "#     console = logging.StreamHandler()\n",
    "#     console.setLevel(logging.INFO)\n",
    "#     console.setFormatter(formatter)\n",
    "\n",
    "    # handler: file\n",
    "    timestr = time.strftime('%Y%m%d_%H:%M:%S')\n",
    "    file_name = 'log/{}_{}.log'.format(name, timestr)\n",
    "\n",
    "    file_handler = logging.FileHandler(file_name)\n",
    "    file_handler.setLevel(logging.INFO)\n",
    "    file_handler.setFormatter(formatter)\n",
    "\n",
    "    # wrap\n",
    "    logger.handlers.clear()\n",
    "#     logger.addHandler(console)\n",
    "    logger.addHandler(file_handler)\n",
    "    return logger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. scheduler simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lm = nn.Linear(2,3)\n",
    "    def forward(self, x):\n",
    "        return self.lm(x)\n",
    "\n",
    "test_model = TestModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fa0818b74d0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "warmup_epoch = 1\n",
    "total_epoch = 5\n",
    "n_iter = 200 \n",
    "n_annealing_iter = (total_epoch-warmup_epoch)*n_iter\n",
    "n_cycle = 5\n",
    "\n",
    "max_lr = 0.01; min_lr = 0.0001;\n",
    "base_lr = max_lr / (warmup_epoch*n_iter)\n",
    "bias = min_lr * (1/base_lr)\n",
    "\n",
    "####################### scheduler1\n",
    "lr_ls = []\n",
    "optimizer = torch.optim.Adam(test_model.parameters(), lr=base_lr)\n",
    "\n",
    "lambda1 = lambda x: bias+x\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda1)\n",
    "\n",
    "j=0\n",
    "for e in range(total_epoch):\n",
    "    if e == warmup_epoch:\n",
    "        optimizer = torch.optim.Adam(test_model.parameters(), lr=optimizer.param_groups[0]['lr']/4)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=int(n_annealing_iter/n_cycle), T_mult=1, eta_min=min_lr)\n",
    "    for _ in range(n_iter):\n",
    "        j+=1\n",
    "        lr_ls.append(scheduler.get_last_lr()[0])\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "plt.plot(lr_ls)\n",
    "plt.scatter(range(len(lr_ls)), lr_ls, s=0.3, c='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class net(nn.Module):\n",
    "    def __init__(self, voc_size, hidn_size, emb_size=300):\n",
    "        super().__init__()\n",
    "        self.pos_id = TEXT.vocab.stoi['positive']\n",
    "        self.neg_id = TEXT.vocab.stoi['negative']\n",
    "\n",
    "        self.voc_size = voc_size\n",
    "        self.emb_size = emb_size\n",
    "        self.hidn_size = hidn_size\n",
    "        self.emb = nn.Embedding(num_embeddings=voc_size, embedding_dim=emb_size) # in: (bs, seq_len); out: (bs, seq_len, emb_size)\n",
    "        self.lstm = nn.LSTM(input_size=emb_size, hidden_size=hidn_size, bidirectional=True, dropout=0.2, batch_first=True) # in: (bs, seq, dim); hidn in: (num_layers * num_directions, batch, hidden_size)\n",
    "        self.lm_out = nn.Linear(hidn_size*2+emb_size, voc_size) # input concatenated_out: (seq_len, bs, hidn_dim) -> permute: (bs, seq_len, hidn_dim) \n",
    "\n",
    "    def init_state(self, bs):\n",
    "        return (torch.zeros(size=(2, bs, self.hidn_size)), torch.zeros(size=(2, bs, self.hidn_size)))\n",
    "        \n",
    "    def forward(self, x, prev_state, label):\n",
    "        state_h, state_c = prev_state\n",
    "        bs = len(x)\n",
    "\n",
    "        # processing label part\n",
    "        label[label==1] = self.pos_id # label: (1, bs)\n",
    "        label[label==0] = self.neg_id\n",
    "        \n",
    "        label_emb = self.emb(label.view(1, -1)) # shape: (seq_len=1, bs, emb_size)\n",
    "        label_emb = label_emb.expand(x.size()[1]-2, bs, self.emb_size) # shape: (seq_len-2, bs, emb_size)\n",
    "        label_emb = label_emb.permute(1, 0, -1)\n",
    "        \n",
    "        # processing hidden state part\n",
    "        emb = self.emb(x) # shape: (bs, seq_len, emb_size)\n",
    "        out, (state_h, state_c) = self.lstm(emb, (state_h[:,:bs,:].contiguous(), state_c[:,:bs,:].contiguous()))\n",
    "        \n",
    "        forward_out = out[:, :, :self.hidn_size] # shape: (bs, seq, hidn_dim)\n",
    "        backward_out = out[:, :, self.hidn_size:]\n",
    "        concat_h = torch.cat([forward_out[:,:-2,:], backward_out[:,2:,:]], dim=2) # shape: (bs, seq_len-2, hidn*num_dir)\n",
    "        \n",
    "        # concat label & concatenated hidn state\n",
    "        final_in = torch.cat([concat_h, label_emb], dim=2) # shape: (bs, seq_len-2, hidn_dim*2+emb+size)\n",
    "        final_out = self.lm_out(final_in)  # shape: (bs, seq_len-2, voc_size)\n",
    "\n",
    "        return final_out, (state_h, state_c)\n",
    "\n",
    "\n",
    "def init_weight(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        if 'emb' == name:\n",
    "            continue\n",
    "        if 'weight' in name:\n",
    "            nn.init.xavier_normal_(param.data)\n",
    "        if 'bias' in name:\n",
    "            nn.init.constant_(param.data, 0)\n",
    "\n",
    "def save_model(model, f='0930_biLSTM_50epoch_label_cosine_annealing.model'):\n",
    "    fn = 'source/{}.pkl'.format(f)\n",
    "    torch.save(model.state_dict(), fn)\n",
    "\n",
    "def repackage_hidden(h):\n",
    "    if type(h) == torch.Tensor:\n",
    "        return h.detach()\n",
    "    else:\n",
    "        return tuple(repackage_hidden(v) for v in h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "fn = 'source/1001_sample_pos_sentences.pkl'\n",
    "with open(fn, 'rb') as f:\n",
    "    length_pos_sample_dict = pickle.load(f)\n",
    "\n",
    "fn = 'source/1001_sample_neg_sentences.pkl'\n",
    "with open(fn, 'rb') as f:\n",
    "    length_neg_sample_dict = pickle.load(f)\n",
    "\n",
    "def init_weight(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        try:\n",
    "            if 'emb' == name:\n",
    "                continue\n",
    "            if 'weight' in name:\n",
    "                nn.init.xavier_normal_(param.data)\n",
    "            if 'bias' in name:\n",
    "                nn.init.constant_(param.data, 0)\n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "def reverse_token(tensor_):\n",
    "    return ' '.join([TEXT.vocab.itos[i] for i in tensor_])\n",
    "\n",
    "def check_pos_neg(model, logger):\n",
    "    \"\"\"\n",
    "    pos, neg label에 따라 token의 분포가 다른지 확인\n",
    "    \"\"\"\n",
    "\n",
    "    def return_pred_review(model, data_, label_, is_label=True):\n",
    "        \"\"\"\n",
    "        return logit for each sequence\n",
    "        - out: shape (bs*seq_len, voc_len)\n",
    "        \"\"\"\n",
    "        device = 'cuda'\n",
    "        bs = len(label_)\n",
    "        model.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            data_ = data_.to(device)\n",
    "            prev_state = model.init_state(bs=bs)\n",
    "            prev_state = list(map(lambda x: x.to(device), prev_state))\n",
    "            if is_label:\n",
    "                label_ = label_.to(device)\n",
    "                out, prev_state = model(data_, prev_state, label_)\n",
    "            else:\n",
    "                out, prev_state = model(data_, prev_state)\n",
    "        return out\n",
    "\n",
    "    def _make_batch_data(ls_value):\n",
    "        \"\"\"\n",
    "        batch_iterator에 사용되는 함수\n",
    "        10 quntile 글자 단위로 묶여 있는 배치 return\n",
    "        \"\"\"\n",
    "        source = torch.nn.utils.rnn.pad_sequence([torch.LongTensor(ls) for ls in ls_value], batch_first=True)\n",
    "        return source\n",
    "\n",
    "    def batch_iterator(full_dict, is_pos=True):\n",
    "        \"\"\"\n",
    "        dict사용하여 batch data 생성하는 iterator\n",
    "        \"\"\"\n",
    "        for k, v in full_dict.items():\n",
    "            source = _make_batch_data(v)\n",
    "            if is_pos:\n",
    "                labels = torch.ones(len(source), dtype=torch.long)\n",
    "            else:\n",
    "                labels = torch.zeros(len(source), dtype=torch.long)\n",
    "            yield source, labels\n",
    "    \n",
    "    generated_label = []\n",
    "    for batch, label in batch_iterator(length_pos_sample_dict, is_pos=True):\n",
    "        out = return_pred_review(model, batch, label, is_label=True)\n",
    "        generated_label.append(out)\n",
    "        \n",
    "    generated_ls_neg = []\n",
    "    for batch, label in batch_iterator(length_pos_sample_dict, is_pos=False):\n",
    "        out = return_pred_review(model, batch, label)\n",
    "        generated_ls_neg.append(out)\n",
    "        \n",
    "    for i in range(10):\n",
    "        logger.info('pos == neg?: {}'.format(torch.all(generated_label[i] == generated_ls_neg[i])))\n",
    "\n",
    "\n",
    "def train(model, data_iter, device, logger, warmup_epoch, total_epoch, n_cycle, max_lr=0.01, min_lr=0.0001, j=0, f='tag', q=0.8):\n",
    "    \"\"\"\n",
    "    parameters\n",
    "    ----------\n",
    "    epoch: epoch for train lr\n",
    "    j: epoch for log\n",
    "    \"\"\"\n",
    "    model.to(device)\n",
    "    loss_func = nn.CrossEntropyLoss()\n",
    "    \n",
    "    ####################### scheduler\n",
    "    n_iter = len(data_iter) # annealing starting point: 200/1000\n",
    "    n_annealing_iter = (total_epoch-warmup_epoch)*n_iter\n",
    "    base_lr = max_lr / (warmup_epoch*n_iter)\n",
    "    bias = min_lr * (1/base_lr)\n",
    "    lambda1 = lambda x: bias+x\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=base_lr)\n",
    "\n",
    "    scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda1)\n",
    "\n",
    "    for e in range(total_epoch):\n",
    "        if e == warmup_epoch:\n",
    "            optimizer = torch.optim.SGD(model.parameters(), lr=optimizer.param_groups[0]['lr'])\n",
    "            scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=int(n_annealing_iter/n_cycle), T_mult=1, eta_min=min_lr)\n",
    "        j +=1\n",
    "        total_loss = 0\n",
    "\n",
    "        for i, batch in enumerate(data_iter, 1):\n",
    "            model.train()\n",
    "            batch_x, label = map(lambda x: x.to(device), [batch.text, batch.label])\n",
    "            batch_y = batch_x[:, 1:-1].to(device)\n",
    "            del batch\n",
    "            \n",
    "            prev_state = model.init_state(bs=len(batch_x))\n",
    "            prev_state = repackage_hidden(prev_state)\n",
    "            prev_state = list(map(lambda x: x.to(device), prev_state))\n",
    "            out, prev_state = model(batch_x, prev_state, label)\n",
    "\n",
    "            ###################################################### sample\n",
    "            x, y = torch.where(batch_y > 1) # special token id: 0,1,2,3\n",
    "            target_token_len = len(x)\n",
    "            sample_n = int(target_token_len*q)\n",
    "\n",
    "            # sample token idx\n",
    "            token_idx = torch.randperm(target_token_len)[:sample_n]\n",
    "\n",
    "            # select target tokens from target\n",
    "            batch_y = batch_y[x[token_idx], y[token_idx]]\n",
    "            out = out[x[token_idx], y[token_idx], :]\n",
    "            ###################################################### sample\n",
    "            optimizer.zero_grad()\n",
    "            loss = loss_func(out, batch_y)\n",
    "            # loss = loss/len(batch_y_)\n",
    "            total_loss += loss\n",
    "\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            if i%10 == 0:\n",
    "                logger.info(total_loss/i)\n",
    "                logger.info('epoch: {}'.format(j))\n",
    "                logger.info('lr: {}'.format(scheduler.get_last_lr()[0]))\n",
    "                logger.info('x')\n",
    "                logger.info(reverse_token(torch.argmax(out, dim=1).detach()))\n",
    "                gc.collect()        \n",
    "        # save model for each epoch\n",
    "        save_model(model, f= f + '_' + str(j) +'.model')\n",
    "        \n",
    "        logger.info(total_loss/i)\n",
    "        logger.info('epoch: {}'.format(j))\n",
    "        logger.info('x')\n",
    "        logger.info(reverse_token(torch.argmax(out, dim=1).detach()))\n",
    "        logger.info('y')\n",
    "        logger.info(reverse_token(batch_y))\n",
    "        check_pos_neg(model, logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "f = 'test'\n",
    "logger = get_logger(f)\n",
    "\n",
    "## label model\n",
    "model = net(voc_size=len(TEXT.vocab), emb_size=300, hidn_size=50)\n",
    "model.apply(init_weight)\n",
    "\n",
    "# load weight\n",
    "# fn = './source/' + '1005_label_model_review_15.model.pkl'\n",
    "# model.load_state_dict(torch.load(fn, map_location=device))\n",
    "\n",
    "model.emb.weight.data.copy_(TEXT.vocab.vectors)\n",
    "model.emb.weight.requires_grad = False\n",
    "train(model, data_iter, device, logger, warmup_epoch=1, total_epoch=50, n_cycle=5, max_lr=0.5, min_lr=0.0008, j=0, f=f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch37",
   "language": "python",
   "name": "torch37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
