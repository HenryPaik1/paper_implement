{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import sentencepiece as spm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "vocab_file = '/home/henry/Documents/wrapper/transformer-evolution/transformer/kowiki.model'\n",
    "vocab = spm.SentencePieceProcessor()\n",
    "vocab.load(vocab_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. vocab\n",
    "- Word Piece Model\n",
    "    - 단어와 subword unit으로 나눔\n",
    "    - 단어의 시작을 특수문자; subword unit은 space로 나눔;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_dir = '/home/henry/Documents/wrapper/transformer-evolution/ratings_train.txt'\n",
    "# lines = []; outputs = [];\n",
    "# with open(data_dir, \"r\") as f:\n",
    "#     for idx, line in enumerate(f):\n",
    "#         if idx == 0:\n",
    "#             continue\n",
    "#         if idx == 4:\n",
    "#             break\n",
    "#         temp = line.split()\n",
    "#         lines.append(' '.join(temp[1:-1]))\n",
    "#         outputs.append(temp[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = [\n",
    "  \"겨울은 추워요.\",\n",
    "  \"감기 조심하세요.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁겨울', '은', '▁추', '워', '요', '.']\n",
      "['▁감', '기', '▁조', '심', '하', '세', '요', '.']\n"
     ]
    }
   ],
   "source": [
    "inputs = []\n",
    "for line in lines:\n",
    "    pieces = vocab.encode_as_pieces(line)\n",
    "    ids = vocab.encode_as_ids(line)\n",
    "    inputs.append(torch.tensor(ids))\n",
    "    print(pieces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([3091, 3604,  206, 3958, 3760, 3590]), tensor([ 212, 3605,   53, 3832, 3596, 3682, 3760, 3590])]\n"
     ]
    }
   ],
   "source": [
    "print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3091, 3604,  206, 3958, 3760, 3590,    0,    0],\n",
      "        [ 212, 3605,   53, 3832, 3596, 3682, 3760, 3590]]) torch.Size([2, 8])\n"
     ]
    }
   ],
   "source": [
    "inputs = torch.nn.utils.rnn.pad_sequence(inputs, batch_first=True, padding_value=0)\n",
    "print(inputs, inputs.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. embedding\n",
    "\n",
    "### 2.1. word embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_vocab = len(vocab)\n",
    "d_hidn = 128\n",
    "nn_emb = nn.Embedding(num_embeddings=n_vocab, embedding_dim=d_hidn)\n",
    "\n",
    "# torch.Size([2, 8, 128])\n",
    "input_embs = nn_emb(inputs) # 임베딩 레이어에 input "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. position embedding\n",
    "- $PE(pos, 2i) = sin(\\frac{pos}{1E+4^{2i / d_{model}}}),$\n",
    "- $PE(pos, 2i+1) = cos(\\frac{pos}{1E+4^{2i / d_{model}}}),$\n",
    "- i: embedding vector에서 idx\n",
    "- pos: sentence에서 position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sinusoid_encoding_table(n_seq, d_hidn):\n",
    "    \"\"\"\n",
    "    n_seq: seq_len\n",
    "    d_hidn: sinusoid table dim \n",
    "    \"\"\"\n",
    "    def _cal_angle(pos, i_hidn):\n",
    "        return pos / np.power(10000, 2 * (i_hidn // 2) / d_hidn)\n",
    "    \n",
    "    def _get_posi_angle_vec(pos):\n",
    "        \"\"\"\n",
    "        sentence의 pos 하나(즉 단어 하나)에 대해 embedding; feature1, feature2, ...., feature128 \n",
    "        즉, sequence의 각 position을 128차원으로 position embedding\n",
    "        예컨대, 첫번째 자리 pos embedding은 정해져 있으므로, 첫번째 자리에 어떤 단어가 들어오든, \n",
    "        해당 pos embedding이 word embedding에 더해짐\n",
    "        \"\"\"\n",
    "        return [_cal_angle(pos, i_hidn) for i_hidn in range(d_hidn)]\n",
    "    \n",
    "    # seq_pos: Word의 sentence 내의 위치 = i\n",
    "    sinusoid_table = np.array([_get_posi_angle_vec(seq_pos) for seq_pos in range(n_seq)])\n",
    "    sinusoid_table[:, 0::2] = np.sin(sinusoid_table[:, 0::2])\n",
    "    sinusoid_table[:, 1::2] = np.cos(sinusoid_table[:, 1::2])\n",
    "    \n",
    "    return sinusoid_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 128)\n"
     ]
    }
   ],
   "source": [
    "# 64개 단어가 하나의 sentence; 128차원 posion임베딩;\n",
    "n_seq = 64\n",
    "pos_encoding = get_sinusoid_encoding_table(n_seq, d_hidn)\n",
    "print(pos_encoding.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# row: sentence에서 위치(pos)\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.pcolormesh(pos_encoding, cmap='twilight_shifted')\n",
    "plt.xlabel('embd_feature')\n",
    "plt.xlim([0, d_hidn])\n",
    "plt.ylabel('word_pos')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. pos embd + word embd\n",
    "- 의문: pos embd도 train 필요? Nope\n",
    "- batch_size & seq_len만큼 position mat 생성\n",
    "- position mat에서 padding 위치의 value는 0처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_encoding = torch.FloatTensor(pos_encoding)\n",
    "nn_pos = nn.Embedding.from_pretrained(pos_encoding, freeze=True) # layer; lookup table\n",
    "# >> Embedding(64, 128)\n",
    "\n",
    "position = torch.arange(inputs.size(1), device=inputs.device, dtype=inputs.dtype)\n",
    "# >> tensor([0, 1, 2, 3, 4, 5, 6, 7])\n",
    "position = position.expand(inputs.size())\n",
    "# >> tensor([[0, 1, 2, 3, 4, 5, 6, 7],\n",
    "#            [0, 1, 2, 3, 4, 5, 6, 7]])\n",
    "position = position.contiguous() + 1 # pad=0이므로 1을 더해 pos에 0없앰\n",
    "# >> tensor([[1, 2, 3, 4, 5, 6, 7, 8],\n",
    "#            [1, 2, 3, 4, 5, 6, 7, 8]])\n",
    "pos_mask = inputs.eq(0) # find elems equal to 0 = pad\n",
    "# tensor([[False, False, False, False, False, False,  True,  True],\n",
    "#         [False, False, False, False, False, False, False, False]])\n",
    "\n",
    "position.masked_fill_(pos_mask, 0) # pad는 position 정보도 주지 않음 <- idx 0의 weight를 동일하게 부여\n",
    "# tensor([[1, 2, 3, 4, 5, 6, 0, 0],\n",
    "#         [1, 2, 3, 4, 5, 6, 7, 8]])\n",
    "\n",
    "pos_embs = nn_pos(position)\n",
    "# pos_embs.shape \n",
    "# >> torch.Size([2, 8, 128]) # batch_size, sequence_len, emb_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3091, 3604,  206, 3958, 3760, 3590,    0,    0],\n",
      "        [ 212, 3605,   53, 3832, 3596, 3682, 3760, 3590]])\n",
      "tensor([[1, 2, 3, 4, 5, 6, 0, 0],\n",
      "        [1, 2, 3, 4, 5, 6, 7, 8]])\n",
      "torch.Size([2, 8, 128])\n",
      "torch.Size([2, 8, 128])\n"
     ]
    }
   ],
   "source": [
    "print(inputs) # embeddimg idx coresponding to the word\n",
    "print(position)\n",
    "print(pos_embs.size())\n",
    "\n",
    "input_vector = input_embs + pos_embs\n",
    "print(input_vector.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Scale Dot Product Attention\n",
    "$$\n",
    "Attention(Q, K, V) = softmax_k(\\dfrac{QK^T}{\\sqrt{d_k}})V\n",
    "$$\n",
    "- 왜 scale? \n",
    "    - d_k는 key vector의 dim. \n",
    "    - depth가 깊다면, $QK^T$ 값이 커짐\n",
    "> \"The dot-product attention is scaled by a factor of square root of the depth. This is done because for large values of depth, the dot product grows large in magnitude pushing the softmax function where it has small gradients resulting in a very hard softmax.\"\n",
    "(https://www.tensorflow.org/tutorials/text/transformer)\n",
    "\n",
    "- detail: 내적은 두 벡터의 크기 * 둘 간의 cosin angle\n",
    "    - $cos \\theta = \\dfrac{A \\dot B}{|A||B|}$\n",
    "    - key dim으로 정규화하면 값이 너무 커지는 것을 방지할 수 있음(https://physics.stackexchange.com/questions/252086/dot-product-approaches-zero-as-the-magnitude-of-the-vectors-increase)\n",
    "- key, query, value? \n",
    "    - 기존 attention 모델은, decoder time step t의 hidden state와 encoder의 모든 time step의 hidden state간의 score를 산출. \n",
    "    - 그리고 그 score를 다시 encoder의 hidden state에 곱하여 weight를 주고, 합산하여 context vector를 산출. \n",
    "    - 위 context vector는, time step t의 hidden state와 concat.\n",
    "    - concat된 vector는 feedforward 통과하여 time step t의 출력값\n",
    "    - 이를 transformer와 비교해보자면, score은 **value**(but value vector 따로 있음), decoder의 hidden state는 **query**, encoder의 hidden state는 **key**에 해당.\n",
    "    \n",
    ">  \"Traditionally, the attention weights were the relevance of the encoder hidden states (values) in processing the decoder state (query) and were calculated based on the encoder hidden states (keys) and the decoder hidden state (query).\"(https://mlexplained.com/2017/12/29/attention-is-all-you-need-explained/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Encoder attention layer는 self attention이므로, Key, Value vector가 모두 자기 자신"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = input_vector\n",
    "K = input_vector\n",
    "V = input_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- attn_mask: key padding indice 마스킹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_mask = inputs.eq(0).unsqueeze(1).expand(Q.size(0), Q.size(1), Q.size(1))\n",
    "# >> torch.Size([2, 8, 8])\n",
    "# inputs.eq(0) <- 0과 동일한 indice\n",
    "# inputs.eq(0).unsqueeze(1) <- dim에 1차원 추가\n",
    "# # >> torch.Size([2, 1, 8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Q.k^T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 8, 8])\n",
      "tensor([[179.5888,  41.7893,  55.7287,  49.2325,  36.9820,  35.9830,  72.3760,\n",
      "          72.3760],\n",
      "        [ 41.7893, 166.6653,  48.7700,  33.3297,  21.7528,  30.6943,  42.4888,\n",
      "          42.4888],\n",
      "        [ 55.7287,  48.7700, 184.7157,  47.0776,  44.6705,  19.4141,  65.6235,\n",
      "          65.6235],\n",
      "        [ 49.2325,  33.3297,  47.0776, 167.9512,  53.2116,   8.3903,  64.6899,\n",
      "          64.6899],\n",
      "        [ 36.9820,  21.7528,  44.6705,  53.2116, 197.3110,  84.3212,  48.9055,\n",
      "          48.9055],\n",
      "        [ 35.9830,  30.6943,  19.4141,   8.3903,  84.3212, 196.9775,  49.1287,\n",
      "          49.1287],\n",
      "        [ 72.3760,  42.4888,  65.6235,  64.6899,  48.9055,  49.1287, 237.8780,\n",
      "         237.8780],\n",
      "        [ 72.3760,  42.4888,  65.6235,  64.6899,  48.9055,  49.1287, 237.8780,\n",
      "         237.8780]], grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "scores = torch.matmul(Q, K.transpose(-1, -2))\n",
    "print(scores.size())\n",
    "print(scores[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. scale\n",
    "- $1/\\sqrt{d_k}$\n",
    "- d_head? k, q, v vector에 weight mat을 곱한 뒤의 dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_head = 64\n",
    "scores = scores.mul(1/d_head**0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 mask\n",
    "- score matrix\n",
    "    - col: key\n",
    "    - row: query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 2.2449e+01,  5.2237e+00,  6.9661e+00,  6.1541e+00,  4.6227e+00,\n",
       "           4.4979e+00, -1.0000e+09, -1.0000e+09],\n",
       "         [ 5.2237e+00,  2.0833e+01,  6.0962e+00,  4.1662e+00,  2.7191e+00,\n",
       "           3.8368e+00, -1.0000e+09, -1.0000e+09],\n",
       "         [ 6.9661e+00,  6.0962e+00,  2.3089e+01,  5.8847e+00,  5.5838e+00,\n",
       "           2.4268e+00, -1.0000e+09, -1.0000e+09],\n",
       "         [ 6.1541e+00,  4.1662e+00,  5.8847e+00,  2.0994e+01,  6.6514e+00,\n",
       "           1.0488e+00, -1.0000e+09, -1.0000e+09],\n",
       "         [ 4.6227e+00,  2.7191e+00,  5.5838e+00,  6.6514e+00,  2.4664e+01,\n",
       "           1.0540e+01, -1.0000e+09, -1.0000e+09],\n",
       "         [ 4.4979e+00,  3.8368e+00,  2.4268e+00,  1.0488e+00,  1.0540e+01,\n",
       "           2.4622e+01, -1.0000e+09, -1.0000e+09],\n",
       "         [ 9.0470e+00,  5.3111e+00,  8.2029e+00,  8.0862e+00,  6.1132e+00,\n",
       "           6.1411e+00, -1.0000e+09, -1.0000e+09],\n",
       "         [ 9.0470e+00,  5.3111e+00,  8.2029e+00,  8.0862e+00,  6.1132e+00,\n",
       "           6.1411e+00, -1.0000e+09, -1.0000e+09]],\n",
       "\n",
       "        [[ 2.8982e+01,  9.0554e+00,  8.1452e+00,  7.2475e+00,  1.0899e+01,\n",
       "           7.3969e+00,  8.2242e+00,  7.1360e+00],\n",
       "         [ 9.0554e+00,  2.5131e+01,  6.7855e+00,  9.0694e+00,  8.6217e+00,\n",
       "           5.7723e+00,  4.3850e+00,  4.7790e+00],\n",
       "         [ 8.1452e+00,  6.7855e+00,  2.0220e+01,  4.9853e+00,  6.4141e+00,\n",
       "           4.3975e+00,  5.3926e+00,  4.5407e+00],\n",
       "         [ 7.2475e+00,  9.0694e+00,  4.9853e+00,  2.3836e+01,  9.7101e+00,\n",
       "           4.5231e+00,  5.6046e+00,  5.3434e+00],\n",
       "         [ 1.0899e+01,  8.6217e+00,  6.4141e+00,  9.7101e+00,  2.8935e+01,\n",
       "           8.7005e+00,  1.0494e+01,  9.8796e+00],\n",
       "         [ 7.3969e+00,  5.7723e+00,  4.3975e+00,  4.5231e+00,  8.7005e+00,\n",
       "           1.8178e+01,  8.0187e+00,  4.1451e+00],\n",
       "         [ 8.2242e+00,  4.3850e+00,  5.3926e+00,  5.6046e+00,  1.0494e+01,\n",
       "           8.0187e+00,  2.6042e+01,  1.0383e+01],\n",
       "         [ 7.1360e+00,  4.7790e+00,  4.5407e+00,  5.3434e+00,  9.8796e+00,\n",
       "           4.1451e+00,  1.0383e+01,  2.4457e+01]]],\n",
       "       grad_fn=<MaskedFillBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.masked_fill_(attn_mask, -1e9)\n",
    "# mask padded area\n",
    "# torch.Size([2, 8, 8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. softmax\n",
    "- https://stackoverflow.com/questions/49036993/pytorch-softmax-what-dimension-to-use\n",
    "- https://blog.csdn.net/qq_36097393/article/details/89319643\n",
    "- dim=-1이면 가장 높은 차원 기준 softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 8, 8])\n"
     ]
    }
   ],
   "source": [
    "attn_prob = nn.Softmax(dim=-1)(scores) # dim 유지\n",
    "print(attn_prob.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4. attn_prov * V "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 8, 128])\n"
     ]
    }
   ],
   "source": [
    "context = torch.matmul(attn_prob, V)\n",
    "print(context.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Multi-Head attn\n",
    "- d_hidn = embedding layer 아웃풋의 dim\n",
    "    - embedding dim\n",
    "- d_head = Q, K, V의 dim\n",
    "    - embedding된 input값이\n",
    "- d_hidn > d_head: 연산량 감소하기 위함 eg. 128 > 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 8, 128])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q = input_vector\n",
    "K = input_vector\n",
    "V = input_vector\n",
    "Q.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- input을 multi head로 복제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = Q.size(0)\n",
    "d_hidn = 128 # embedding dim\n",
    "d_head = 64 # K, Q, V의 dim\n",
    "n_head = 2\n",
    "\n",
    "# linear feed forward layer\n",
    "W_Q = nn.Linear(d_hidn, n_head * d_head)\n",
    "W_K = nn.Linear(d_hidn, n_head * d_head)\n",
    "W_V = nn.Linear(d_hidn, n_head * d_head)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. multi-head K, Q, V input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 8, 64])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bs, n_seq, n_head, d_head\n",
    "# torch.Size([2, 8, 2, 64])\n",
    "W_Q(Q).view(batch_size, -1, n_head, d_head).shape\n",
    "# torch.Size([2, 2, 8, 64]) \n",
    "W_Q(Q).view(batch_size, -1, n_head, d_head).transpose(1,2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 8, 64])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (bs, n_head, n_seq, d_head)\n",
    "Qs = W_Q(Q).view(batch_size, -1, n_head, d_head).transpose(1, 2)\n",
    "Ks = W_K(K).view(batch_size, -1, n_head, d_head).transpose(1, 2)\n",
    "Vs = W_V(V).view(batch_size, -1, n_head, d_head).transpose(1, 2)\n",
    "Vs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. multi-head attn mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.Size([2, 8, 8]) -> torch.size([2, 2, 8, 8])\n",
    "attn_mask = attn_mask.unsqueeze(1).repeat(1, n_head, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# torch.Size([2, 2, 8, 64]) * torch.Size([2, 2, 64, 8])\n",
    "# output: torch.Size([2, 2, 8, 8])\n",
    "scores = torch.matmul(Qs, Ks.transpose(-1, -2))\n",
    "scores = scores.masked_fill(attn_mask, -np.inf)\n",
    "\n",
    "# bs, n_head, [n_q_seq, n_k_seq]\n",
    "# torch.Size([2, 2, 8, 8])\n",
    "attn_prob = nn.Softmax(dim=-1)(scores)\n",
    "\n",
    "# bs, n_head, n_q_seq, d_v\n",
    "# torch.Size([2, 2, 8, 64])\n",
    "context = torch.matmul(attn_prob, Vs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transpose: bs, n_q_seq, n_head, d_v\n",
    "# view: bs, n_q_seq, n_head * d_v\n",
    "# -> torch.Size([2, 8, 128])\n",
    "context = context\\\n",
    ".transpose(1, 2)\\\n",
    ".contiguous()\\\n",
    ".view(batch_size, -1, n_head * d_head)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.Size([2, 8, 128])\n",
    "# bs, [n_q_seq, n_hidn] <- embedding된 input size와 동일\n",
    "enc_output = nn.Linear(n_head * d_head, d_hidn)(context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. feedforward\n",
    "### 6.1. 1st linear feedforward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1 = nn.Conv1d(in_channels=d_hidn, \\\n",
    "                  out_channels=d_hidn * 4, kernel_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bs, [n_hidn, n_q_seq]\n",
    "# torch.Size([2, 128, 8])\n",
    "enc_output.transpose(1,2).shape\n",
    "\n",
    "# torch.Size([2, 512, 8])\n",
    "enc_output = conv1(enc_output.transpose(1,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2. activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_output = F.gelu(enc_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3. 2nd linear feedforward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv2 = nn.Conv1d(in_channels=d_hidn * 4, \\\n",
    "                  out_channels=d_hidn, \\\n",
    "                  kernel_size=1)\n",
    "# torch.Size([2, 128, 8])\n",
    "enc_output = conv2(enc_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# calss\n",
    "# 1. common class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from types import SimpleNamespace\n",
    "config = dict({\n",
    "    \"n_enc_vocab\": len(vocab),\n",
    "    \"n_dec_vocab\": len(vocab),\n",
    "    \"n_enc_seq\": 256,\n",
    "    \"n_dec_seq\": 256,\n",
    "    \"n_layer\": 6,\n",
    "    \"d_hidn\": 256,\n",
    "    \"i_pad\": 0,\n",
    "    \"d_ff\": 1024,\n",
    "    \"n_head\": 4,\n",
    "    \"d_head\": 64,\n",
    "    \"dropout\": 0.1,\n",
    "    \"layer_norm_epsilon\": 1e-12,\n",
    "    \"n_output\": 2\n",
    "})\n",
    "print(config)\n",
    "config = SimpleNamespace(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sinusoid_encoding_table(n_seq, d_hidn):\n",
    "    def cal_angle(position, i_hidn):\n",
    "        return position / np.power(10000, 2 * (i_hidn // 2) / d_hidn)\n",
    "    def get_posi_angle_vec(position):\n",
    "        return [cal_angle(position, i_hidn) for i_hidn in range(d_hidn)]\n",
    "\n",
    "    sinusoid_table = np.array([get_posi_angle_vec(i_seq) for i_seq in range(n_seq)])\n",
    "    sinusoid_table[:, 0::2] = np.sin(sinusoid_table[:, 0::2])  # even index sin \n",
    "    sinusoid_table[:, 1::2] = np.cos(sinusoid_table[:, 1::2])  # odd index cos\n",
    "\n",
    "    return sinusoid_table\n",
    "\n",
    "def get_attn_pad_mask(seq_q, seq_k, i_pad):\n",
    "    \"\"\"\n",
    "    key_vector의 pad열은 모두 0으로 padding\n",
    "    - row: query token\n",
    "    - col: key token\n",
    "    \n",
    "    params\n",
    "    - seq_q, seq_k: [bs, len_seq]\n",
    "    \"\"\"\n",
    "    batch_size, len_q = seq_q.size()\n",
    "    batch_size, len_k = seq_k.size()\n",
    "    pad_attn_mask = seq_k.data.eq(i_pad).unsqueeze(1).expand(batch_size, len_q, len_k)  # key vector에 masking한 것을, len_q만큼 늘려줌(row wise)\n",
    "    return pad_attn_mask\n",
    "\n",
    "def get_attn_decoder_mask(seq):\n",
    "    subsequent_mask = torch.ones_like(seq).unsqueeze(-1).expand(seq.size(0), seq.size(1), seq.size(1))\n",
    "    subsequent_mask = subsequent_mask.triu(diagonal=1) # upper triangular part of a matrix(2-D)\n",
    "    return subsequent_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### attn pad mask example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 1, 0],\n",
       "        [2, 2, 1, 0]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_key_seq = torch.randint(0,3, size=(2, 4)) # [bs, q_seq_len]\n",
    "sample_key_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2, 1, 0]],\n",
       "\n",
       "        [[2, 2, 1, 0]]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_key_seq.unsqueeze(1) # [2,4] -> [2, 1, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2, 1, 0],\n",
       "         [1, 2, 1, 0],\n",
       "         [1, 2, 1, 0],\n",
       "         [1, 2, 1, 0]],\n",
       "\n",
       "        [[2, 2, 1, 0],\n",
       "         [2, 2, 1, 0],\n",
       "         [2, 2, 1, 0],\n",
       "         [2, 2, 1, 0]]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_key_seq.unsqueeze(1).expand(2, 4, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[False, False, False,  True],\n",
       "         [False, False, False,  True],\n",
       "         [False, False, False,  True],\n",
       "         [False, False, False,  True]],\n",
       "\n",
       "        [[False, False, False,  True],\n",
       "         [False, False, False,  True],\n",
       "         [False, False, False,  True],\n",
       "         [False, False, False,  True]]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_pad = sample_key_seq.eq(0).unsqueeze(1).expand(2, 4, 4) # attn_pad\n",
    "attn_pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PoswiseFeedForwardNet(nn.Module):\n",
    "    \"\"\"\n",
    "    variables\n",
    "    - inputs: output of attn layer(attn_outputs)\n",
    "        - shape:[bs, len_query_seq, d_hidn]\n",
    "    return\n",
    "    - output\n",
    "    \"\"\"\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "\n",
    "        self.conv1 = nn.Conv1d(in_channels=self.config.d_hidn, out_channels=self.config.d_ff, kernel_size=1)\n",
    "        self.conv2 = nn.Conv1d(in_channels=self.config.d_ff, out_channels=self.config.d_hidn, kernel_size=1)\n",
    "        self.active = F.gelu\n",
    "        self.dropout = nn.Dropout(config.dropout)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # (bs, d_ff, n_seq)\n",
    "        output = self.active(self.conv1(inputs.transpose(1, 2)))\n",
    "        # (bs, n_seq, d_hidn)\n",
    "        output = self.conv2(output).transpose(1, 2)\n",
    "        output = self.dropout(output)\n",
    "        # (bs, n_seq, d_hidn)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PoswiseFeedForwardNet example code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 9., 3., 7., 9., 3., 2., 4.],\n",
       "         [4., 4., 1., 2., 4., 5., 1., 9.],\n",
       "         [5., 9., 4., 8., 9., 5., 4., 5.],\n",
       "         [5., 7., 2., 3., 5., 2., 8., 2.]],\n",
       "\n",
       "        [[1., 1., 9., 6., 1., 2., 9., 9.],\n",
       "         [4., 3., 8., 7., 5., 3., 1., 1.],\n",
       "         [5., 6., 7., 3., 5., 8., 7., 1.],\n",
       "         [8., 8., 8., 3., 3., 9., 2., 4.]]])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# multihead output: [bs, seq_len, d_hidn]\n",
    "# how to apply 1d conv to NLP in torch: https://gist.github.com/spro/c87cc706625b8a54e604fb1024106556\n",
    "attn_outputs = torch.randint(1, 10, size=[2, 4, 8]).float()\n",
    "attn_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 128, 4])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input dim [bs, d_hidn, seq_len]\n",
    "conv1d_1st = nn.Conv1d(in_channels=8, out_channels=128, kernel_size=1)(attn_outputs.transpose(2, 1))\n",
    "conv1d_1st.shape # [bs, out_dim, seq_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 8, 4])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv1d_2nd = nn.Conv1d(in_channels=128, out_channels=8, kernel_size=1)(conv1d_1st)\n",
    "conv1d_2nd.shape # [bs, d_hidn, seq_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 8])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv1d_2nd.transpose(2,1).shape # [bs, seq_len, d_hidn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScaledDotProductAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    variables\n",
    "    - V, Q: [bs, len_seq, d_hidn]\n",
    "    - attn_prob: [bs, n_head, len_query_seq, len_key_seq]\n",
    "    - context: [bs, n_head, len_query_seq, d_hidn]\n",
    "    calculate\n",
    "    - scores: Q * K.T = [bs, len_seq, d_hidn] * [bs, d_hidn, len_seq]\n",
    "        - shape: [bs, len_seq, len_seq]\n",
    "    - attn_prob: dropout(softmax(score))\n",
    "    - context: torch.matmul(attn_prob, Value vector)\n",
    "    \"\"\"\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.dropout = nn.Dropout(config.dropout)\n",
    "        self.scale = 1 / (self.config.d_head ** 0.5)\n",
    "    \n",
    "    def forward(self, Q, K, V, attn_mask):\n",
    "        scores = torch.matmul(Q, K.transpose(-1, -2)).mul_(self.scale)\n",
    "        scores.masked_fill_(attn_mask, -1e9) # softmax에서 sum!=0 위해 -1e9\n",
    "        \n",
    "        attn_prob = nn.Softmax(dim=-1)(scores)\n",
    "        attn_prob = self.dropout(attn_prob)\n",
    "        \n",
    "        context = torch.matmul(attn_prob, V)\n",
    "        # (bs, n_head, n_q_seq, d_v), (bs, n_head, n_q_seq, n_v_seq)\n",
    "        return context, attn_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scaled dot example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[False, False, False,  True],\n",
       "         [False, False, False,  True],\n",
       "         [False, False, False,  True],\n",
       "         [False, False, False,  True]],\n",
       "\n",
       "        [[False, False, False,  True],\n",
       "         [False, False, False,  True],\n",
       "         [False, False, False,  True],\n",
       "         [False, False, False,  True]]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_pad # [bs, q_seq_len, k_seq_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[4., 8., 6., 5.],\n",
       "         [2., 9., 7., 2.],\n",
       "         [5., 9., 9., 8.],\n",
       "         [9., 9., 4., 4.]],\n",
       "\n",
       "        [[9., 9., 8., 7.],\n",
       "         [4., 8., 6., 8.],\n",
       "         [8., 3., 2., 7.],\n",
       "         [6., 8., 7., 5.]]])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = torch.randint_like(attn_pad, 2, 10, dtype=torch.float)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 4.0000e+00,  8.0000e+00,  6.0000e+00, -1.0000e+09],\n",
       "         [ 2.0000e+00,  9.0000e+00,  7.0000e+00, -1.0000e+09],\n",
       "         [ 5.0000e+00,  9.0000e+00,  9.0000e+00, -1.0000e+09],\n",
       "         [ 9.0000e+00,  9.0000e+00,  4.0000e+00, -1.0000e+09]],\n",
       "\n",
       "        [[ 9.0000e+00,  9.0000e+00,  8.0000e+00, -1.0000e+09],\n",
       "         [ 4.0000e+00,  8.0000e+00,  6.0000e+00, -1.0000e+09],\n",
       "         [ 8.0000e+00,  3.0000e+00,  2.0000e+00, -1.0000e+09],\n",
       "         [ 6.0000e+00,  8.0000e+00,  7.0000e+00, -1.0000e+09]]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.masked_fill_(attn_pad, -1e9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.5876e-02, 8.6681e-01, 1.1731e-01, 0.0000e+00],\n",
       "         [8.0254e-04, 8.8009e-01, 1.1911e-01, 0.0000e+00],\n",
       "         [9.0747e-03, 4.9546e-01, 4.9546e-01, 0.0000e+00],\n",
       "         [4.9832e-01, 4.9832e-01, 3.3577e-03, 0.0000e+00]],\n",
       "\n",
       "        [[4.2232e-01, 4.2232e-01, 1.5536e-01, 0.0000e+00],\n",
       "         [1.5876e-02, 8.6681e-01, 1.1731e-01, 0.0000e+00],\n",
       "         [9.9087e-01, 6.6764e-03, 2.4561e-03, 0.0000e+00],\n",
       "         [9.0031e-02, 6.6524e-01, 2.4473e-01, 0.0000e+00]]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_prob = nn.Softmax(dim=-1)(scores.float())\n",
    "attn_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[2., 5., 9., 6.],\n",
       "         [2., 9., 5., 5.],\n",
       "         [5., 4., 6., 5.],\n",
       "         [8., 2., 7., 4.]],\n",
       "\n",
       "        [[4., 9., 6., 8.],\n",
       "         [7., 6., 4., 6.],\n",
       "         [6., 4., 3., 3.],\n",
       "         [6., 5., 6., 7.]]])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V = torch.randint(2, 10, size=(2,4,4)).float()\n",
    "V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0000, 1.7336, 0.2346, 0.0000],\n",
       "         [0.0000, 1.7602, 0.0000, 0.0000],\n",
       "         [0.0181, 0.9909, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0067, 0.0000]],\n",
       "\n",
       "        [[0.8446, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [1.9817, 0.0134, 0.0000, 0.0000],\n",
       "         [0.0000, 1.3305, 0.4895, 0.0000]]])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.Dropout()(attn_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 6.9365, 12.8820, 10.9002,  9.9093],\n",
       "         [ 1.9933,  4.9832,  8.9698,  5.9799]],\n",
       "\n",
       "        [[ 5.2429,  8.8446,  6.0000,  7.6893],\n",
       "         [ 1.5347,  1.2243,  0.8944,  0.9579],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 9.3134,  7.9829,  5.3219,  7.9829]]])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context = torch.matmul(nn.Dropout()(attn_prob), V)\n",
    "context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    weight mat\n",
    "    - W_Q, W_K, W_K: [d_hidn, n_head*d_head]\n",
    "    \n",
    "    vectors\n",
    "    - q_s, k_s, v_s: [bs, n_head, seq_len, d_head]\n",
    "    \n",
    "    calculate\n",
    "    - eg. W_Q(Q): Q * W_Q = [bs, seq_len, d_hidn] * [d_hidn, n_head*d_head] \n",
    "                            = [bs, seq_len, n_head*d_head] \n",
    "                            <- ([seq_len * d_head] mat = embedded Q가 n_head만큼 있음) * bs\n",
    "    - eg. W_Q(Q).view(bs, -1, n_head, d_head).transpose(1, 2) = (bs, n_head, -1=seq_len, d_head) \n",
    "    \n",
    "    return\n",
    "    - output: [bs, len_query_seq, d_hidn]\n",
    "    - attn_prob: [bs, n_head, len_query_seq, len_key_seq]\n",
    "    \"\"\"\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        \n",
    "        # n_head의 K, Q, V 한번에 생성\n",
    "        self.W_Q = nn.Linear(self.config.d_hidn, self.config.n_head * self.config.d_head)\n",
    "        self.W_K = nn.Linear(self.config.d_hidn, self.config.n_head * self.config.d_head)\n",
    "        self.W_V = nn.Linear(self.config.d_hidn, self.config.n_head * self.config.d_head)\n",
    "        self.scaled_dot_attn = ScaledDotProductAttention(self.config)\n",
    "        self.linear = nn.Linear(self.config.n_head * self.config.d_head, self.config.d_hidn)\n",
    "        self.dropout = nn.Dropout(config.dropout)\n",
    "    # n_head의 K, Q, V 한번에 생성\n",
    "    def forward(self, Q, K, V, attn_mask):\n",
    "        batch_size = Q.size(0)\n",
    "        q_s = self.W_Q(Q).view(batch_size, -1, self.config.n_head, self.config.d_head).transpose(1,2)\n",
    "        k_s = self.W_K(K).view(batch_size, -1, self.config.n_head, self.config.d_head).transpose(1,2)\n",
    "        v_s = self.W_V(V).view(batch_size, -1, self.config.n_head, self.config.d_head).transpose(1,2)\n",
    "\n",
    "        attn_mask = attn_mask.unsqueeze(1).repeat(1, self.config.n_head, 1, 1)\n",
    "\n",
    "        context, attn_prob = self.scaled_dot_attn(q_s, k_s, v_s, attn_mask)\n",
    "        context = context.transpose(1, 2).contiguous().view(batch_size, -1, self.config.n_head * self.config.d_head) # [bs, seq_len, n_head * d_head]\n",
    "        output = self.linear(context) # 각 head의 output은 position wise sum이므로 해당 calculate 가능\n",
    "        output = self.dropout(output)\n",
    "        \n",
    "        return output, attn_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### multihead forward part example\n",
    "- eg.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [bs, len_seq, embed_dim=d_hidn]\n",
    "input_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 8, 1024])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q = input_vector # [bs, seq_len, d_hidn]\n",
    "Qs = nn.Linear(in_features=128, out_features=8*128)(Q)\n",
    "Qs.shape # [bs, seq_len, n_head*d_hidn]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- eg.2: context vector 변환\n",
    "    - reshape & transpose했을 때 `[19, 23,  7, 92, 66, 10, 15, 73, 19,  5, 81, 80, 49, 92, 79]` 변화\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[19, 23,  7, 92, 66, 10, 15, 73, 19,  5, 81, 80, 49, 92, 79],\n",
       "        [29, 78, 13, 54, 29, 49, 56, 55,  5, 47, 87, 92, 34, 18, 75],\n",
       "        [72, 68, 10, 57, 34, 47, 46, 63,  3, 49, 40, 87, 79, 92, 41],\n",
       "        [ 5, 96, 76, 14, 73, 64, 90, 41, 69, 18, 95, 75, 96, 72, 30]],\n",
       "\n",
       "       [[91, 42, 91, 98,  1, 17, 64, 33, 35, 26,  2, 94, 33, 23, 53],\n",
       "        [43, 61, 49, 26, 86, 10, 61, 90, 89, 24, 68, 21, 28, 12, 64],\n",
       "        [57, 68, 77, 74, 10,  3, 99, 29, 81, 97, 24, 65, 63, 91, 73],\n",
       "        [93,  1, 47, 60, 90, 49, 21, 90, 96, 41, 29, 53, 59, 57, 42]]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.random.randint(1, 100, size=(2,4,3*5)) # [bs, seq_len, n_head * d_head]\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[19, 23,  7, 92, 66],\n",
       "         [10, 15, 73, 19,  5],\n",
       "         [81, 80, 49, 92, 79]],\n",
       "\n",
       "        [[29, 78, 13, 54, 29],\n",
       "         [49, 56, 55,  5, 47],\n",
       "         [87, 92, 34, 18, 75]],\n",
       "\n",
       "        [[72, 68, 10, 57, 34],\n",
       "         [47, 46, 63,  3, 49],\n",
       "         [40, 87, 79, 92, 41]],\n",
       "\n",
       "        [[ 5, 96, 76, 14, 73],\n",
       "         [64, 90, 41, 69, 18],\n",
       "         [95, 75, 96, 72, 30]]],\n",
       "\n",
       "\n",
       "       [[[91, 42, 91, 98,  1],\n",
       "         [17, 64, 33, 35, 26],\n",
       "         [ 2, 94, 33, 23, 53]],\n",
       "\n",
       "        [[43, 61, 49, 26, 86],\n",
       "         [10, 61, 90, 89, 24],\n",
       "         [68, 21, 28, 12, 64]],\n",
       "\n",
       "        [[57, 68, 77, 74, 10],\n",
       "         [ 3, 99, 29, 81, 97],\n",
       "         [24, 65, 63, 91, 73]],\n",
       "\n",
       "        [[93,  1, 47, 60, 90],\n",
       "         [49, 21, 90, 96, 41],\n",
       "         [29, 53, 59, 57, 42]]]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.reshape(2,-1,3,5) # [bs, seq_len, n_head, d_head]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[19, 23,  7, 92, 66],\n",
       "         [29, 78, 13, 54, 29],\n",
       "         [72, 68, 10, 57, 34],\n",
       "         [ 5, 96, 76, 14, 73]],\n",
       "\n",
       "        [[10, 15, 73, 19,  5],\n",
       "         [49, 56, 55,  5, 47],\n",
       "         [47, 46, 63,  3, 49],\n",
       "         [64, 90, 41, 69, 18]],\n",
       "\n",
       "        [[81, 80, 49, 92, 79],\n",
       "         [87, 92, 34, 18, 75],\n",
       "         [40, 87, 79, 92, 41],\n",
       "         [95, 75, 96, 72, 30]]],\n",
       "\n",
       "\n",
       "       [[[91, 42, 91, 98,  1],\n",
       "         [43, 61, 49, 26, 86],\n",
       "         [57, 68, 77, 74, 10],\n",
       "         [93,  1, 47, 60, 90]],\n",
       "\n",
       "        [[17, 64, 33, 35, 26],\n",
       "         [10, 61, 90, 89, 24],\n",
       "         [ 3, 99, 29, 81, 97],\n",
       "         [49, 21, 90, 96, 41]],\n",
       "\n",
       "        [[ 2, 94, 33, 23, 53],\n",
       "         [68, 21, 28, 12, 64],\n",
       "         [24, 65, 63, 91, 73],\n",
       "         [29, 53, 59, 57, 42]]]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.transpose(A.reshape(2,-1,3,5), axes=[0,2,1,3]) # [bs, n_head, seq_len, d_head]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. encoder clasas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    variables\n",
    "    - attn_outputs: [bs, lne_query_seq, d_hidn]\n",
    "    - ffn_outputs: [bs, lne_query_seq, d_hidn]\n",
    "    \"\"\"\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "\n",
    "        self.self_attn = MultiHeadAttention(self.config)\n",
    "        self.layer_norm1 = nn.LayerNorm(self.config.d_hidn, eps=self.config.layer_norm_epsilon)\n",
    "        self.pos_ffn = PoswiseFeedForwardNet(self.config)\n",
    "        self.layer_norm2 = nn.LayerNorm(self.config.d_hidn, eps=self.config.layer_norm_epsilon)\n",
    "    \n",
    "    def forward(self, inputs, attn_mask):\n",
    "        att_outputs, attn_prob = self.self_attn(inputs, inputs, inputs, attn_mask)\n",
    "        att_outputs = self.layer_norm1(inputs + att_outputs)\n",
    "        \n",
    "        ffn_outputs = self.pos_ffn(att_outputs)\n",
    "        ffn_outputs = self.layer_norcm2(ffn_outputs + att_outputs)\n",
    "        \n",
    "        return ffn_outputs, attn_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \"\"\"\n",
    "    variable\n",
    "    - outputs: embeded output; [bs, seq_len, d_hidn];\n",
    "    - final outputs: result context vector of attn layers; [bs, seq_len, d_hidn];\n",
    "    - attn_mask: [bs, seq_q_len, seq_k_len]\n",
    "    - attn_prob: [bs, seq_q_len, d_hidn]\n",
    "    \"\"\"\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "\n",
    "        self.enc_emb = nn.Embedding(self.config.n_enc_vocab, self.config.d_hidn)\n",
    "        sinusoid_table = torch.FloatTensor(get_sinusoid_encoding_table(self.config.n_enc_seq + 1, self.config.d_hidn))\n",
    "        self.pos_emb = nn.Embedding.from_pretrained(sinusoid_table, freeze=True)\n",
    "\n",
    "        self.layers = nn.ModuleList([EncoderLayer(self.config) for _ in range(self.config.n_layer)])\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        positions = torch.arange(inputs.size(1), device=inputs.device, dtype=inputs.dtype).expand(inputs.size(0), inputs.size(1)).contiguous() + 1\n",
    "        pos_mask = inputs.eq(self.config.i_pad)\n",
    "        positions.masked_fill_(pos_mask, 0)\n",
    "\n",
    "        outputs = self.enc_emb(inputs) + self.pos_emb(positions)\n",
    "        \n",
    "        attn_mask = get_attn_pad_mask(inputs, inputs, self.config.i_pad)\n",
    "\n",
    "        attn_probs = []\n",
    "        for layer in self.layers:\n",
    "            outputs, attn_prob = layer(outputs, attn_mask) # outputs = ffn_outputs\n",
    "            attn_probs.append(attn_prob)\n",
    "        return outputs, attn_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### position example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = torch.randint(1,10,size=(2, 4, 8))\n",
    "torch.arange(inputs.size(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3, 4],\n",
       "        [1, 2, 3, 4]])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(inputs.size(1)).expand(2, 4).contiguous()+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Decoder class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    1st attn layer: self attention layer\n",
    "    - Q, K, V = decoder inputs\n",
    "    2nd attn layer: decoder encoder attention layer\n",
    "    - Q, K, V = 1st attn layer outputs, encoder outputs, encoder outputs\n",
    "    \n",
    "    MultiHeadAttention return\n",
    "    - attn_outputs: [bs, seq_q_len, d_hidn]\n",
    "    - attn_prob: [bs, n_head, seq_q_len, ]\n",
    "    \"\"\"\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        \n",
    "        self.self_attn = MultiHeadAttention(self.config)\n",
    "        self.layer_norm1 = nn.LayerNorm(self.config.d_hidn, eps=self.config.layer_norm_epsilon)\n",
    "        \n",
    "        self.dec_enc_attn = MultiHeadAttention(self.config)\n",
    "        self.layer_norm2 = nn.LayerNorm(self.config.d_hidn, eps=self.config.layer_norm.epsilon)\n",
    "        \n",
    "        self.pos_feedforward = PoswiseFeedForwardNet(self.config)\n",
    "        self.layer_norm3 = nn.LayerNorm(self.config.d_hidn, eps=self.config.layer_norm_epsilon)\n",
    "        \n",
    "    def forward(self, dec_inputs, enc_outputs, self_attn_mask, dec_enc_attn_mask):\n",
    "        self_attn_outputs, self_attn_prob = self.self_attn(dec_inputs, dec_inputs, dec_inputs, self_attn_mask) \n",
    "        self_attn_outputs = self.layer_norm1(dec_inputs + self_attn_outputs) # LaterNorm(residual)\n",
    "        \n",
    "        dec_enc_attn_outputs, dec_enc_attn_prob = self.dec_enc_attn(self_attn_outputs, enc_outputs, enc_outputs, dec_enc_attn_mask)\n",
    "        dec_enc_attn_outputs = self.layer_norm2(self_attn_outputs + dec_enc_attn_outputs) # LaterNorm(residual)\n",
    "        \n",
    "        # (bs, n_dec_seq, d_hidn)\n",
    "        ffn_outputs = self.pos_feedforward(dec_enc_attn_outputs)\n",
    "        ffn_outputs = self.layer_norm3(dec_enc_attn_outputs + ffn_outputs)\n",
    "        \n",
    "        # (bs, n_dec_seq, d_hidn), (bs, n_head, n_dec_seq, n_dec_seq), (bs, n_head, n_dec_seq, n_enc_seq)\n",
    "        return ffn_outputs, self_attn_prob, dec_enc_attn_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        \n",
    "        self.dec_emb = nn.Embedding(self.config.n_dec_vocab, self.config.d_hidn)\n",
    "        sinusoid_table = torch.FloatTensor(get_sinusoid_encoding_table(self.config.n_dec_seq + 1, self.config.d_hidn))\n",
    "        self.pos_emb = nn.Embedding.from_pretrained(sinusoid_table, freeze=True)\n",
    "        self.layers = nn.ModuleList([DecoderLayer(self.config) for _ in range(self.config.n_layer)])\n",
    "        \n",
    "    def forward(self, dec_inputs, enc_inputs, enc_outputs):\n",
    "        position = torch.arange(dec_inputs.size(1), device=dec_inputs.device, dtype=dec_inputs.dtype)\\\n",
    "                        .expands(dec_inputs.size(0), dec_inputs.size(1)).contiguouse() + 1\n",
    "        pos_mask = dec_inputs.eq(self.config.i_pad)\n",
    "        positions.masked_fill_(pos_mask, 0)\n",
    "        \n",
    "        # (bs, n_dec_seq, d_hidn)\n",
    "        dec_outputs = self.dec_emb(dec_inputs) + self.pos_emb(positions)\n",
    "        \n",
    "        # (bs, n_dec_seq, n_dec_seq)\n",
    "        dec_attn_pad_mask = get_attn_pad_mask(dec_inputs, dec_inputs, self.config.i_pad) # get_attn_pad_mask(seq_q, seq_k, i_pad)\n",
    "        dec_attn_decoder_mask = get_attn_decoder_mask(dec_inputs) # 대각선 기준 위 mask\n",
    "        \n",
    "        dec_self_attn_mask = torch.gt((dec_attn_pad_mask + dec_attn_decoder_mask), 0)\n",
    "        dec_enc_attn_mask = get_attn_pad_mask(dec_inputs, enc_inputs, self.config.i_pad)\n",
    "        \n",
    "        self_attn_probs, dec_enc_attn_probs = [], []\n",
    "        for layer in self.layers:\n",
    "            # (bs, n_dec_seq, d_hidn), (bs, n_dec_seq, n_dec_seq), (bs, d_dec_seq, n_enc_seq)\n",
    "            dec_outputs, self_attn_prob, dec_enc_attn_prob = layer(dec_outputs, enc_outputs, dec_self_attn_mask, dec_enc_attn_mask)\n",
    "            self_attn_probs.append(self_attn_prob)\n",
    "            dec_enc_attn_probs.append(dec_enc_attn_prob)\n",
    "        return dec_outputs, self_attn_probs, dec_enc_attn_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config \n",
    "        \n",
    "        self.encoder = Encoder(self.config)\n",
    "        self.decoder = Decoder(self.config)\n",
    "        \n",
    "    def forward(self, enc_inputs, dec_inputs):\n",
    "        # (bs, n_enc_seq, d_hidn), (bs, n_head, n_enc_seq, n_enc_seq)\n",
    "        enc_outputs, enc_self_attn_probs = self.encoder(enc_inputs)\n",
    "        # (bs, n_seq, d_hidn), (bs, n_head, n_dec_seq, n_dec_seq), (bs, n_head, n_dec_seq, n_enc_seq)\n",
    "        dec_outputs, dec_self_attn_probs, dec_enc_attn_probs = self.decoder(dec_inputs, enc_inputs, enc_outputs)\n",
    "        # (bs, n_dec_seq, n_dec_vocab), (bs, n_head, n_enc_seq, n_enc_seq), (bs, n_head, n_dec_seq, n_dec_seq), (bs, n_head, n_dec_seq, n_enc_seq)\n",
    "        return dec_outputs, enc_self_attn_probs, dec_self_attn_probs, dec_enc_attn_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Naver movie clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieClf(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.transformer = Transformer(self.config)\n",
    "        self.projection = nn.Linear(self.config.d_hidn, self.config.n_output, bias=False)\n",
    "        \n",
    "    def forward(self, enc_inputs, dec_inputs):\n",
    "        dec_outputs, ence_self_attn_probs, dec_self_attn_probs, dec_enc_attn_probs = self.transformer(enc_inputs, dec_inputs)\n",
    "        dec_outputs, _ = torch.max(dec_outputs, dim=1)\n",
    "        logit = self.projection(dec_outputs)\n",
    "        \n",
    "        return logits, enc_self_attn_probs, dec_self_attn_probs, dec_enc_attn_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 데이터셋\n",
    "    - https://pytorch.org/tutorials/beginner/data_loading_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = 'ratings_test.txt'\n",
    "data = []\n",
    "with open(fn) as f:\n",
    "    while True:\n",
    "        line = f.readline()\n",
    "        if not line: \n",
    "            break\n",
    "        _, t, l = line.split('\\t')\n",
    "        l = l.split('\\n')[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "sentence = []\n",
    "d = []\n",
    "\n",
    "line_cnt = 0\n",
    "fn = 'ratings_test.txt'\n",
    "data = []\n",
    "with open(fn) as f:\n",
    "    while True:\n",
    "        line = f.readline()\n",
    "        d.append(line)\n",
    "        line_cnt += 1\n",
    "        if line_cnt == 1:\n",
    "            continue\n",
    "        if not line: \n",
    "            break\n",
    "        _, t, l = line.split('\\t')\n",
    "        l = l.split('\\n')[0]\n",
    "        labels.append(int(l))\n",
    "        sentence.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, vocab, infile):\n",
    "        self.vocab = vocab\n",
    "        self.labels = []\n",
    "        self.sentences = []\n",
    "\n",
    "        line_cnt = 0\n",
    "        fn = 'ratings_test.txt'\n",
    "        with open(fn) as f:\n",
    "            while True:\n",
    "                line = f.readline()\n",
    "                line_cnt += 1\n",
    "                if line_cnt == 1:\n",
    "                    continue\n",
    "                if not line: \n",
    "                    break\n",
    "                _, t, l = line.split('\\t')\n",
    "                l = l.split('\\n')[0]\n",
    "                self.labels.append(int(l))\n",
    "                self.sentences.append(t)\n",
    "        \n",
    "    def __len__(self):\n",
    "        assert len(self.labels) == len(self.sentences)\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        return (torch.tensor(self.labels[item]), torch.tensor(self.sentences[item]), torch.tensor([self.vocab.piece_to_id(\"[BOS]\")]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_fn(inputs):\n",
    "    labels, enc_inputs, dec_inputs = list(zip(*inputs))\n",
    "    enc_inputs = torch.nn.utils.rnn.pad_sequence(enc_inputs, batch_first=True, padding_value=0)\n",
    "    dec_inputs = torch.nn.utils.rnn.pad_sequence(dec_inputs, batch_first=True, padding_value=0)\n",
    "    batch = [\n",
    "        torch.stack(labels, dim=0),\n",
    "        enc_inputs,\n",
    "        dec_inputs\n",
    "    ]\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "fn =  'ratings_test.txt'\n",
    "train_dataset = MovieDataset(vocab, fn)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=custom_collate_fn)\n",
    "\n",
    "fn = 'ratings_test.txt'\n",
    "test_dataset = MovieDataset(vocab, fn)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=custom_collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. train\n",
    "- https://discuss.pytorch.org/t/model-eval-vs-with-torch-no-grad/19615/32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_epoch(config, model, data_loader):\n",
    "    matchs = []\n",
    "    model.eval()\n",
    "    \n",
    "    n_word_total = 0\n",
    "    n_correct_total = 0\n",
    "    for i, value in enumerate(data_loader):\n",
    "        labels, enc_inputs, dec_inputs = map(lambda x: x.to(config.device), value) # cpu/gpu tensor\n",
    "        outputs = model(enc_inputs, dec_inputs)\n",
    "        logits = outputs[0]\n",
    "        _, idx = logits.max(dim=1) # return val, idx\n",
    "        match = torch.eq(idx, labels).detach() # detach: \"Returns a new Tensor, detached from the current graph.\"\"\n",
    "        matchs.extend(match.cpu())\n",
    "        acc = np.sum(matchs) / len(matchs) if 0 < len(matchs) else 0\n",
    "    return np.sum(matchs) / len(matchs) if 0 < len(matchs) else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(config, epoch, model, criterion, optimizer, train_loader):\n",
    "    loss_ls = []\n",
    "    model.train()\n",
    "    \n",
    "    for i, value in enumerate(train_loader):\n",
    "        labels, enc_inputs, dec_inputs = map(lambda x: x.to(config.device), value)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(enc_inputs, dec_inputs)\n",
    "        logits = outputs[0]\n",
    "        \n",
    "        loss = criterion(logits, labels)\n",
    "        loss_val= loss.item()\n",
    "        loss_ls.append(loss_val)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    return np.mean(loss_ls) # batch 당 loss 평균"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MovieClf(config)\n",
    "model.to(config.device)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "best_epoch, best_loss, best_score = 0, 0, 0\n",
    "loss_ls, score_ls = [], []\n",
    "for epoch in range(n_epoch):\n",
    "    loss = train_epoch(config, epoch, model, criterion, optimizer, train_loader)\n",
    "    score = eval_epoch(config, model, test_loader)\n",
    "    \n",
    "    loss_ls.append(loss)\n",
    "    scores.append(score)\n",
    "    \n",
    "    if best_score < score:\n",
    "        best_epoch, best_loss, best_score = epoch, loss, score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3",
   "language": "python",
   "name": "py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
